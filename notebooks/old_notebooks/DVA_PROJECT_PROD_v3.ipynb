{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "import spacy\n",
        "import requests"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {\n",
        "    \"Age\": [25],\n",
        "    \"Sex\": [0],\n",
        "    \"Location\": [1],\n",
        "    \"Product_1\": [3258],\n",
        "    \"activity_at_injury\": [\"fall walk\"],\n",
        "    \"object_involved\": [\"bike\"],\n",
        "    \"injury_mechanism\": [\" \"],\n",
        "    \"More details\": [\"fall from bike when riding\"]\n",
        "}\n",
        "\n",
        "sample_df_single_record = pd.DataFrame(data)\n",
        "sample_df_single_record"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 91,
          "data": {
            "text/plain": "   Age  Sex  Location  Product_1 activity_at_injury object_involved  \\\n0   25    0         1       3258          fall walk            bike   \n\n  injury_mechanism                More details  \n0                   fall from bike when riding  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>Location</th>\n      <th>Product_1</th>\n      <th>activity_at_injury</th>\n      <th>object_involved</th>\n      <th>injury_mechanism</th>\n      <th>More details</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3258</td>\n      <td>fall walk</td>\n      <td>bike</td>\n      <td></td>\n      <td>fall from bike when riding</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 91,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730870081159
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bdpt_dict={}\n",
        "bdpt_dict[0]='INTERNAL'\n",
        "bdpt_dict[30]='SHOULDER'\n",
        "bdpt_dict[31]='UPPERTRUNK'\n",
        "bdpt_dict[32]='ELBOW'\n",
        "bdpt_dict[33]='LOWERARM'\n",
        "bdpt_dict[34]='WRIST'\n",
        "bdpt_dict[35]='KNEE'\n",
        "bdpt_dict[36]='LOWERLEG'\n",
        "bdpt_dict[37]='ANKLE'\n",
        "bdpt_dict[38]='PUBICREGION'\n",
        "bdpt_dict[75]='HEAD'\n",
        "bdpt_dict[76]='FACE'\n",
        "bdpt_dict[77]='EYEBALL'\n",
        "bdpt_dict[78]='UPPERTRUNK(OLD)'\n",
        "bdpt_dict[79]='LOWERTRUNK'\n",
        "bdpt_dict[80]='UPPERARM'\n",
        "bdpt_dict[81]='UPPERLEG'\n",
        "bdpt_dict[82]='HAND'\n",
        "bdpt_dict[83]='FOOT'\n",
        "bdpt_dict[84]='25-50% OF BODY'\n",
        "bdpt_dict[85]='ALLPARTSBODY'\n",
        "bdpt_dict[86]='OTHER(OLD)'\n",
        "bdpt_dict[87]='NOTSTATED/UNK'\n",
        "bdpt_dict[88]='MOUTH'\n",
        "bdpt_dict[89]='NECK'\n",
        "bdpt_dict[90]='LOWERARM(OLD)'\n",
        "bdpt_dict[91]='LOWERLEG(OLD)'\n",
        "bdpt_dict[92]='FINGER'\n",
        "bdpt_dict[93]='TOE'\n",
        "bdpt_dict[94]='EAR'"
      ],
      "outputs": [],
      "execution_count": 92,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730870084883
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df_single_record['Narrative_LLM']=sample_df_single_record[\"activity_at_injury\"].astype(str) + ' '+sample_df_single_record[\"injury_mechanism\"].astype(str)+ ' ' + sample_df_single_record[\"object_involved\"].astype(str)\n",
        "sample_df_single_record['Narrative']=sample_df_single_record[\"More details\"]\n",
        "sample_df_single_record_2=sample_df_single_record[[\"Age\",\"Sex\",\"Location\",\"Product_1\"]]\n",
        "sample_df_single_record_2"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 93,
          "data": {
            "text/plain": "   Age  Sex  Location  Product_1\n0   25    0         1       3258",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>Location</th>\n      <th>Product_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3258</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 93,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730870087179
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the SpaCy model\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "sematic_distance=[]\n",
        "\n",
        "for key in bdpt_dict:\n",
        "\n",
        "    #print(key)\n",
        "    #print(i)\n",
        "    word1 = bdpt_dict[key] #\"cut\"\n",
        "    word2 = sample_df_single_record.at[0,'Narrative_LLM'] #\"bike\"\n",
        "\n",
        "    # SpaCy similarity\n",
        "    doc1 = nlp(word1)\n",
        "    doc2 = nlp(word2)\n",
        "    similarity = doc1.similarity(doc2)\n",
        "    sematic_distance.append(similarity)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0\n30\n31\n32\n33\n34\n35\n36\n37\n38\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_7972/2849378550.py:19: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n  similarity = doc1.similarity(doc2)\n"
        }
      ],
      "execution_count": 95,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730870119997
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = sample_df_single_record['Narrative'].fillna('')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [token for token in tokens if token.isalpha() and token not in stopwords.words('english')]\n",
        "    tagged_tokens = nltk.pos_tag(tokens)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token, pos='v') for token, pos in tagged_tokens]\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "sample_df_single_record['Processed_Narrative'] = corpus.apply(preprocess_text)\n",
        "\n",
        "with open('tfidf_vectorizer.pkl', 'rb') as file:\n",
        "    loaded_vectorizer = pickle.load(file)\n",
        "\n",
        "# Use the loaded vectorizer to transform new data\n",
        "tfidf_matrix = loaded_vectorizer.transform(sample_df_single_record['Processed_Narrative'])\n",
        "\n",
        "# Convert the TF-IDF matrix to a DataFrame\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=loaded_vectorizer.get_feature_names_out())"
      ],
      "outputs": [],
      "execution_count": 96,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730870130090
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_LLM = sample_df_single_record['Narrative_LLM'].fillna('')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [token for token in tokens if token.isalpha() and token not in stopwords.words('english')]\n",
        "    tagged_tokens = nltk.pos_tag(tokens)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token, pos='v') for token, pos in tagged_tokens]\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "sample_df_single_record['Processed_Narrative_LLM'] = corpus_LLM.apply(preprocess_text)\n",
        "\n",
        "# Create a TfidfVectorizer object\n",
        "with open('tfidf_vectorizer_LLM.pkl', 'rb') as file:\n",
        "    loaded_vectorizer_llm = pickle.load(file)\n",
        "\n",
        "# Use the loaded vectorizer to transform new data\n",
        "tfidf_matrix_LLM = loaded_vectorizer_llm.transform(sample_df_single_record['Processed_Narrative_LLM'])\n",
        "\n",
        "# Convert the TF-IDF matrix to a DataFrame\n",
        "tfidf_df_LLM = pd.DataFrame(tfidf_matrix_LLM.toarray(), columns=loaded_vectorizer_llm.get_feature_names_out())\n",
        "tfidf_df_LLM=tfidf_df_LLM.add_suffix('_LLM')\n",
        "\n",
        "# Concatenate the TF-IDF features with your existing data\n",
        "\n",
        "#data_ready = pd.concat([data_core_sample, tfidf_df_LLM], axis=1)"
      ],
      "outputs": [],
      "execution_count": 97,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730870133053
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"Body_Part\": [25],\n",
        "}\n",
        "df_body= pd.DataFrame(data)\n",
        "data_ready = pd.concat([sample_df_single_record_2[['Age','Sex','Location']],df_body,sample_df_single_record_2[['Product_1']], tfidf_df,tfidf_df_LLM], axis=1)"
      ],
      "outputs": [],
      "execution_count": 98,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730870137041
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('X_scaler.pkl', 'rb') as file:\n",
        "    scaler = pickle.load(file)\n",
        "\n",
        "prob_out={}\n",
        "\n",
        "with open('xgboost_tfidf_LLM_v2.pkl', 'rb') as file:\n",
        "    best_model = pickle.load(file)\n",
        "\n",
        "k=0\n",
        "\n",
        "for i in bdpt_dict:\n",
        "    X_test_final.at[0,'Body_Part']=i\n",
        "    #print(X_test_final)\n",
        "    temp=pd.DataFrame()\n",
        "    temp['sematic_distance']=[sematic_distance[k]]\n",
        "    #print(temp)\n",
        "    data_ready_2=pd.concat([temp,data_ready], axis=1)\n",
        "    #print(data_ready_2)\n",
        "\n",
        "    X_test_scaled = scaler.transform(data_ready_2.select_dtypes(include=['number']))\n",
        "    X_test_final=pd.DataFrame(X_test_scaled, columns=data_ready_2.select_dtypes(include=['number']).columns)\n",
        "    y_prob = best_model.predict_proba(X_test_final)[:, 1][0]\n",
        "    #print(y_prob)\n",
        "    prob_out[str(i)]=y_prob\n",
        "    k+=1\n",
        "\n",
        "prob_out"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 109,
          "data": {
            "text/plain": "{'0': 0.1570866,\n '30': 0.1570866,\n '31': 0.39655313,\n '32': 0.1570866,\n '33': 0.39655313,\n '34': 0.1570866,\n '35': 0.1570866,\n '36': 0.39655313,\n '37': 0.1570866,\n '38': 0.39655313,\n '75': 0.1570866,\n '76': 0.1570866,\n '77': 0.39655313,\n '78': 0.19196437,\n '79': 0.39655313,\n '80': 0.39655313,\n '81': 0.39655313,\n '82': 0.1570866,\n '83': 0.1570866,\n '84': 0.1570866,\n '85': 0.39655313,\n '86': 0.19196437,\n '87': 0.21336558,\n '88': 0.1570866,\n '89': 0.1570866,\n '90': 0.19196437,\n '91': 0.19196437,\n '92': 0.1570866,\n '93': 0.1570866,\n '94': 0.1570866}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 109,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730870610405
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xxxx\n",
        "def Predict_Body_parts_Prob(Age, Sex, Race,Location,Hispanic, Product_1 ,Alcohol, Drug):\n",
        "    X = np.column_stack([Age, Sex, Race,Location,Hispanic, Product_1 ,Alcohol, Drug])\n",
        "    \n",
        "    return loaded_model.predict_proba(X)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data_ready_2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[102], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_ready_2\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_ready_2' is not defined"
          ]
        }
      ],
      "execution_count": 102,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730870245918
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/anaconda/envs/azureml_py38/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n  warnings.warn(\"Can't initialize NVML\")\nCollecting en-core-web-md==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from en-core-web-md==3.7.1) (3.7.4)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (24.1)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.4)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.8.2)\nRequirement already satisfied: setuptools in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (68.0.0)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.32.3)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.4)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.3.4)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (6.4.0)\nRequirement already satisfied: jinja2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.4)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.3)\nRequirement already satisfied: numpy>=1.19.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.23.5)\nRequirement already satisfied: language-data>=1.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.20.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.0)\nRequirement already satisfied: typing-extensions>=4.6.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.19)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.8.30)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.7)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.5)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.5)\nRequirement already satisfied: marisa-trie>=0.7.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\nInstalling collected packages: en-core-web-md\nSuccessfully installed en-core-web-md-3.7.1\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_md')\n"
        }
      ],
      "execution_count": 87,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}