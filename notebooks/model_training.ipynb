{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1731120966160
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/eric/workspace/omscs/neiss-injury-analysis/.venv/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /home/eric/workspace/omscs/neiss-injury-analysis/.venv/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/eric/workspace/omscs/neiss-injury-analysis/.venv/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/eric/workspace/omscs/neiss-injury-analysis/.venv/lib/python3.10/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /home/eric/workspace/omscs/neiss-injury-analysis/.venv/lib/python3.10/site-packages (from nltk) (4.66.6)\n",
      "Requirement already satisfied: xgboost in /home/eric/workspace/omscs/neiss-injury-analysis/.venv/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in /home/eric/workspace/omscs/neiss-injury-analysis/.venv/lib/python3.10/site-packages (from xgboost) (2.1.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/eric/workspace/omscs/neiss-injury-analysis/.venv/lib/python3.10/site-packages (from xgboost) (2.21.5)\n",
      "Requirement already satisfied: scipy in /home/eric/workspace/omscs/neiss-injury-analysis/.venv/lib/python3.10/site-packages (from xgboost) (1.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CPSC_Case_Number</th>\n",
       "      <th>Treatment_Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Other_Race</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>221032332</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034040</td>\n",
       "      <td>-0.036666</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0.024984</td>\n",
       "      <td>-0.048995</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>-0.020119</td>\n",
       "      <td>-0.058474</td>\n",
       "      <td>-0.022191</td>\n",
       "      <td>0.038710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>221032332</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023124</td>\n",
       "      <td>-0.024773</td>\n",
       "      <td>0.022977</td>\n",
       "      <td>-0.009349</td>\n",
       "      <td>-0.035247</td>\n",
       "      <td>-0.044326</td>\n",
       "      <td>-0.043986</td>\n",
       "      <td>0.037598</td>\n",
       "      <td>-0.028593</td>\n",
       "      <td>0.000559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>221032332</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>-0.074769</td>\n",
       "      <td>0.037170</td>\n",
       "      <td>0.012632</td>\n",
       "      <td>0.035928</td>\n",
       "      <td>0.027713</td>\n",
       "      <td>-0.068887</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>-0.006860</td>\n",
       "      <td>-0.004257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>221032332</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021093</td>\n",
       "      <td>-0.024679</td>\n",
       "      <td>0.015815</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>-0.049645</td>\n",
       "      <td>-0.008986</td>\n",
       "      <td>-0.046884</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>0.033469</td>\n",
       "      <td>0.012299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>221032332</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009391</td>\n",
       "      <td>-0.037633</td>\n",
       "      <td>0.005725</td>\n",
       "      <td>-0.022449</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>-0.003252</td>\n",
       "      <td>-0.032876</td>\n",
       "      <td>0.037961</td>\n",
       "      <td>0.002015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 413 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  CPSC_Case_Number Treatment_Date  Age  Sex  Race Other_Race  \\\n",
       "0           0         221032332     2022-09-24   14    1     0          0   \n",
       "1           0         221032332     2022-09-24   14    1     0          0   \n",
       "2           0         221032332     2022-09-24   14    1     0          0   \n",
       "3           0         221032332     2022-09-24   14    1     0          0   \n",
       "4           0         221032332     2022-09-24   14    1     0          0   \n",
       "\n",
       "   Hispanic  Body_Part  Diagnosis  ...       374       375       376  \\\n",
       "0       0.0         34         71  ...  0.034040 -0.036666  0.008797   \n",
       "1       0.0         34         71  ...  0.023124 -0.024773  0.022977   \n",
       "2       0.0         34         71  ...  0.004684 -0.074769  0.037170   \n",
       "3       0.0         34         71  ...  0.021093 -0.024679  0.015815   \n",
       "4       0.0         34         71  ...  0.009391 -0.037633  0.005725   \n",
       "\n",
       "        377       378       379       380       381       382       383  \n",
       "0  0.024984 -0.048995  0.002708 -0.020119 -0.058474 -0.022191  0.038710  \n",
       "1 -0.009349 -0.035247 -0.044326 -0.043986  0.037598 -0.028593  0.000559  \n",
       "2  0.012632  0.035928  0.027713 -0.068887  0.003097 -0.006860 -0.004257  \n",
       "3  0.002770 -0.049645 -0.008986 -0.046884  0.007277  0.033469  0.012299  \n",
       "4 -0.022449  0.004378  0.006639 -0.003252 -0.032876  0.037961  0.002015  \n",
       "\n",
       "[5 rows x 413 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_10p = pd.read_csv('../data/neiss_10p_sample.csv')\n",
    "embedding=pd.read_csv('../data/gist_embedding_10p_final.csv')\n",
    "data=data_10p.merge(embedding,how='inner',on='CPSC_Case_Number').reset_index(drop=True)\n",
    "data.head(5)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1731121003728
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data['Disposition_recode']=np.nan\n",
    "data.loc[((data['Disposition']==1)), 'Disposition_recode'] = 0\n",
    "data.loc[((data['Disposition']==2)), 'Disposition_recode'] = 1\n",
    "data.loc[((data['Disposition']==4)), 'Disposition_recode'] = 2\n",
    "data.loc[((data['Disposition']==5)), 'Disposition_recode'] = 3\n",
    "data.loc[((data['Disposition']==8)), 'Disposition_recode'] = 4\n",
    "data=data[data['Disposition_recode'].notna()]\n",
    "\n",
    "data['Disposition_recode_2']=0\n",
    "data.loc[((data['Disposition_recode']>0)), 'Disposition_recode_2'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disposition_recode_2\n",
       "0    295967\n",
       "1     33465\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data[(data['Body_Part']!=0) & (data['Body_Part']!=84) & (data['Body_Part']!=85) & (data['Body_Part']!=86) & (data['Body_Part']!=87)]\n",
    "data['Disposition_recode'].value_counts()\n",
    "data['Disposition_recode_2'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1731121014315
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "bdpt_dict={}\n",
    "bdpt_dict[0]='INTERNAL'\n",
    "bdpt_dict[30]='SHOULDER'\n",
    "bdpt_dict[31]='UPPERTRUNK'\n",
    "bdpt_dict[32]='ELBOW'\n",
    "bdpt_dict[33]='LOWERARM'\n",
    "bdpt_dict[34]='WRIST'\n",
    "bdpt_dict[35]='KNEE'\n",
    "bdpt_dict[36]='LOWERLEG'\n",
    "bdpt_dict[37]='ANKLE'\n",
    "bdpt_dict[38]='PUBICREGION'\n",
    "bdpt_dict[75]='HEAD'\n",
    "bdpt_dict[76]='FACE'\n",
    "bdpt_dict[77]='EYEBALL'\n",
    "bdpt_dict[78]='UPPERTRUNK(OLD)'\n",
    "bdpt_dict[79]='LOWERTRUNK'\n",
    "bdpt_dict[80]='UPPERARM'\n",
    "bdpt_dict[81]='UPPERLEG'\n",
    "bdpt_dict[82]='HAND'\n",
    "bdpt_dict[83]='FOOT'\n",
    "bdpt_dict[84]='25-50% OF BODY'\n",
    "bdpt_dict[85]='ALLPARTSBODY'\n",
    "bdpt_dict[86]='OTHER(OLD)'\n",
    "bdpt_dict[87]='NOTSTATED/UNK'\n",
    "bdpt_dict[88]='MOUTH'\n",
    "bdpt_dict[89]='NECK'\n",
    "bdpt_dict[90]='LOWERARM(OLD)'\n",
    "bdpt_dict[91]='LOWERLEG(OLD)'\n",
    "bdpt_dict[92]='FINGER'\n",
    "bdpt_dict[93]='TOE'\n",
    "bdpt_dict[94]='EAR'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1731121020538
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "data['body_string']=data['Body_Part'].map(bdpt_dict)\n",
    "# data['Narrative_LLM']=data[\"activity_at_injury\"].astype(str) + ' '+data[\"injury_mechanism\"].astype(str)+ ' ' + data[\"object_involved\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1731114277211
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (329432, 416)\n",
      "Train set size: 263546 rows\n",
      "Test set size: 65886 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'CPSC_Case_Number', 'Treatment_Date', 'Age', 'Sex',\n",
       "       'Race', 'Other_Race', 'Hispanic', 'Body_Part', 'Diagnosis',\n",
       "       ...\n",
       "       '377', '378', '379', '380', '381', '382', '383', 'Disposition_recode',\n",
       "       'Disposition_recode_2', 'body_string'],\n",
       "      dtype='object', length=416)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_core=data.copy()\n",
    "total_rows, n_columns = data_core.shape\n",
    "\n",
    "test_size = int(total_rows * 0.2)\n",
    "train_size = total_rows - test_size\n",
    "\n",
    "print(f\"Original dataset shape: ({total_rows}, {n_columns})\")\n",
    "print(f\"Train set size: {train_size} rows\")\n",
    "print(f\"Test set size: {test_size} rows\")\n",
    "data_core = data_core.sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle the data\n",
    "\n",
    "data_train = data_core.tail(train_size).reset_index(drop=True)\n",
    "data_test = data_core.head(test_size).reset_index(drop=True)\n",
    "# data_train=data_core.tail(191347).reset_index(drop=True)\n",
    "# data_test=data_core.head(21000).reset_index(drop=True)\n",
    "\n",
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1731114704628
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "drop_list=['Narrative','Unnamed: 0',\n",
    " 'CPSC_Case_Number',\n",
    " 'Treatment_Date','Race',\n",
    " 'Other_Race',\n",
    " 'Hispanic','Diagnosis',\n",
    " 'Other_Diagnosis',\n",
    " 'Body_Part_2',\n",
    " 'Diagnosis_2',\n",
    " 'Other_Diagnosis_2',\n",
    " 'Disposition','Fire_Involvement','Product_2',\n",
    " 'Product_3',\n",
    " 'Alcohol',\n",
    " 'Drug','Stratum',\n",
    " 'PSU',\n",
    " 'Weight',\n",
    " 'Year',\n",
    " 'Month',\n",
    " 'Day',\n",
    " 'Disposition_recode',\n",
    " 'Disposition_recode_2',\n",
    " 'body_string',\n",
    "]\n",
    "\n",
    "drop_list_test=['Narrative','Unnamed: 0',\n",
    " 'CPSC_Case_Number',\n",
    " 'Treatment_Date','Race',\n",
    " 'Other_Race',\n",
    " 'Hispanic','Diagnosis',\n",
    " 'Other_Diagnosis',\n",
    " 'Body_Part_2',\n",
    " 'Diagnosis_2',\n",
    " 'Other_Diagnosis_2',\n",
    " 'Disposition','Fire_Involvement','Product_2',\n",
    " 'Product_3',\n",
    " 'Alcohol',\n",
    " 'Drug','Stratum',\n",
    " 'PSU',\n",
    " 'Weight',\n",
    " 'Year',\n",
    " 'Month',\n",
    " 'Day',\n",
    " 'Disposition_recode',\n",
    " 'Disposition_recode_2',\n",
    " 'body_string',\n",
    "]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Sex', 'Body_Part', 'Location', 'Product_1', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383']\n"
     ]
    }
   ],
   "source": [
    "X = data_train.drop(drop_list, axis=1) \n",
    "y = data_train['Disposition_recode_2']\n",
    "\n",
    "print(list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1731115388172
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/workspace/omscs/neiss-injury-analysis/.venv/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8960780742494612\n",
      "XGBoost F1 Score: 0.33491986401165613\n",
      "XGBoost AUC: 0.8306330305112557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94     59237\n",
      "           1       0.47      0.26      0.33      6649\n",
      "\n",
      "    accuracy                           0.90     65886\n",
      "   macro avg       0.70      0.61      0.64     65886\n",
      "weighted avg       0.88      0.90      0.88     65886\n",
      "\n",
      "Ensemble Accuracy: 0.8960780742494612\n",
      "Ensemble F1 Score: 0.33491986401165613\n",
      "Ensemble AUC: 0.8306330305112557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94     59237\n",
      "           1       0.47      0.26      0.33      6649\n",
      "\n",
      "    accuracy                           0.90     65886\n",
      "   macro avg       0.70      0.61      0.64     65886\n",
      "weighted avg       0.88      0.90      0.88     65886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, roc_auc_score\n",
    "from scipy.stats import mode\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data_train.drop(drop_list, axis=1) \n",
    "y = data_train['Disposition_recode_2']\n",
    "\n",
    "# Encode target variable if it's categorical\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, _, y_train, _ = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test=data_test.drop(drop_list_test, axis=1)\n",
    "y_test=data_test['Disposition_recode_2']\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# Create a scaler for numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.select_dtypes(include=['number']))\n",
    "\n",
    "with open('X_scaler_v6.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test.select_dtypes(include=['number']))\n",
    "\n",
    "# Convert scaled features back to DataFrame\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.select_dtypes(include=['number']).columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.select_dtypes(include=['number']).columns)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_scaled_df, y_train)\n",
    "\n",
    "# Combine scaled numerical features with categorical features\n",
    "X_train_final = X_resampled.copy()\n",
    "X_test_final = X_test_scaled_df.copy()\n",
    "y_train_final=y_resampled.copy()\n",
    "\n",
    "\n",
    "# Define models and their parameter grids for hyperparameter tuning\n",
    "models = {\n",
    "    #'KNN': (KNeighborsClassifier(), {'knn__n_neighbors': [3, 5, 7]}),\n",
    "    #'Random_Forest': (RandomForestClassifier(), {'random_forest__n_estimators': [100, 200], 'random_forest__max_depth': [4, 8]}),\n",
    "    'XGBoost': (XGBClassifier(objective='binary:logistic'), \n",
    "           {'xgboost__learning_rate': [0.1, 0.01, 0.001],            # Step size shrinkage to prevent overfitting\n",
    "            'xgboost__max_depth': [3, 5, 7],                         # Maximum depth of each tree\n",
    "            #'xgboost__n_estimators': [100, 200, 300],                # Number of boosting rounds\n",
    "            #'xgboost__min_child_weight': [1, 3, 5],                  # Minimum sum of instance weight needed in a child\n",
    "            #'xgboost__subsample': [0.6, 0.8,0.9],                   # Subsample ratio of the training instances\n",
    "            #'xgboost__colsample_bytree': [0.6, 0.8, 0.9],            # Subsample ratio of columns when constructing each tree\n",
    "            #'xgboost__gamma': [0.1, 0.5, 1,3],                     # Minimum loss reduction required for a split\n",
    "            #'xgboost__reg_alpha': [0.01, 0.1,0.5,1],                    # L1 regularization term on weights\n",
    "            #'xgboost__reg_lambda': [1, 1.5, 2],                      # L2 regularization term on weights\n",
    "            'xgboost__scale_pos_weight': [1, 5, 10]\n",
    "            }),\n",
    "    #'Logistic_Regression': (LogisticRegression(solver='liblinear'), {'logistic_regression__C': [0.1, 1, 10]}),\n",
    "    #'SVM': (SVC(probability=True), {'svm__C': [0.1, 1, 10], 'svm__kernel': ['linear', 'rbf']}),\n",
    "    #'NN': (MLPClassifier(max_iter=1000), {'nn__hidden_layer_sizes': [(10,), (50,), (100,)], 'nn__activation': ['relu', 'tanh']}),\n",
    "}\n",
    "\n",
    "# Initialize list to store predictions from each model\n",
    "ensemble_predictions = []\n",
    "ensemble_probabilities = []\n",
    "\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "    # Create a pipeline for preprocessing and model training\n",
    "    pipeline = Pipeline([\n",
    "        (model_name.lower(), model)\n",
    "    ])\n",
    "\n",
    "    # Perform hyperparameter tuning using GridSearchCV with AUC score\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='precision',n_jobs=-1)\n",
    "    grid_search.fit(X_train_final, y_train_final)\n",
    "\n",
    "    # Get the best model from the grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Make predictions and predict probabilities on the test set\n",
    "    y_pred = best_model.predict(X_test_final)\n",
    "    y_prob = best_model.predict_proba(X_test_final)[:, 1]  # Probability for the positive class\n",
    "    ensemble_predictions.append(y_pred)\n",
    "    ensemble_probabilities.append(y_prob)\n",
    "\n",
    "    # Evaluate the model using accuracy, F1-score, and AUC\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
    "    print(f\"{model_name} F1 Score: {f1}\")\n",
    "    print(f\"{model_name} AUC: {auc}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Implement ensemble method (majority voting for predictions, average for probabilities)\n",
    "ensemble_predictions = np.array(ensemble_predictions)\n",
    "ensemble_pred_final = mode(ensemble_predictions, axis=0)[0].flatten()\n",
    "\n",
    "# Average the probabilities for the ensemble AUC\n",
    "ensemble_probabilities = np.mean(ensemble_probabilities, axis=0)\n",
    "\n",
    "# Evaluate the ensemble model using accuracy, F1-score, and AUC\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_pred_final)\n",
    "ensemble_f1 = f1_score(y_test, ensemble_pred_final)\n",
    "ensemble_auc = roc_auc_score(y_test, ensemble_probabilities)\n",
    "print(\"Ensemble Accuracy:\", ensemble_accuracy)\n",
    "print(\"Ensemble F1 Score:\", ensemble_f1)\n",
    "print(\"Ensemble AUC:\", ensemble_auc)\n",
    "print(classification_report(y_test, ensemble_pred_final))\n",
    "\n",
    "with open('xgboost_tfidf_LLM_v6.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Location</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.565123</td>\n",
       "      <td>-0.927244</td>\n",
       "      <td>-1.350384</td>\n",
       "      <td>-0.758252</td>\n",
       "      <td>-0.224069</td>\n",
       "      <td>0.811610</td>\n",
       "      <td>0.019274</td>\n",
       "      <td>0.271284</td>\n",
       "      <td>0.136758</td>\n",
       "      <td>0.071753</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.377549</td>\n",
       "      <td>0.849482</td>\n",
       "      <td>0.391997</td>\n",
       "      <td>-1.091326</td>\n",
       "      <td>0.234278</td>\n",
       "      <td>-1.408936</td>\n",
       "      <td>1.093114</td>\n",
       "      <td>-0.670800</td>\n",
       "      <td>0.145674</td>\n",
       "      <td>0.279506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.631854</td>\n",
       "      <td>1.078465</td>\n",
       "      <td>0.453370</td>\n",
       "      <td>-0.758252</td>\n",
       "      <td>-0.192996</td>\n",
       "      <td>-1.025957</td>\n",
       "      <td>-1.113281</td>\n",
       "      <td>-0.942938</td>\n",
       "      <td>0.244664</td>\n",
       "      <td>-0.834023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.673912</td>\n",
       "      <td>0.804057</td>\n",
       "      <td>0.302155</td>\n",
       "      <td>-0.689552</td>\n",
       "      <td>-0.387157</td>\n",
       "      <td>-0.493553</td>\n",
       "      <td>-0.488695</td>\n",
       "      <td>-1.462640</td>\n",
       "      <td>-0.049399</td>\n",
       "      <td>-0.936254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.589855</td>\n",
       "      <td>-0.927244</td>\n",
       "      <td>-1.436277</td>\n",
       "      <td>1.728689</td>\n",
       "      <td>2.144190</td>\n",
       "      <td>1.458991</td>\n",
       "      <td>-0.140287</td>\n",
       "      <td>-0.975067</td>\n",
       "      <td>-1.404018</td>\n",
       "      <td>0.223374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651381</td>\n",
       "      <td>0.207351</td>\n",
       "      <td>-0.125334</td>\n",
       "      <td>1.196148</td>\n",
       "      <td>0.401503</td>\n",
       "      <td>-0.314695</td>\n",
       "      <td>-0.189012</td>\n",
       "      <td>-1.109648</td>\n",
       "      <td>2.615690</td>\n",
       "      <td>-0.022485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.085865</td>\n",
       "      <td>-0.927244</td>\n",
       "      <td>-1.436277</td>\n",
       "      <td>-0.447384</td>\n",
       "      <td>-0.240346</td>\n",
       "      <td>0.025051</td>\n",
       "      <td>-1.192750</td>\n",
       "      <td>0.343443</td>\n",
       "      <td>-2.602726</td>\n",
       "      <td>1.689154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.393289</td>\n",
       "      <td>-1.171166</td>\n",
       "      <td>2.125857</td>\n",
       "      <td>1.701152</td>\n",
       "      <td>0.577964</td>\n",
       "      <td>-0.391780</td>\n",
       "      <td>-0.436157</td>\n",
       "      <td>-0.051245</td>\n",
       "      <td>0.130650</td>\n",
       "      <td>-0.411247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.778851</td>\n",
       "      <td>-0.927244</td>\n",
       "      <td>-1.350384</td>\n",
       "      <td>0.485219</td>\n",
       "      <td>0.853892</td>\n",
       "      <td>-0.909808</td>\n",
       "      <td>-0.211408</td>\n",
       "      <td>0.480258</td>\n",
       "      <td>1.414003</td>\n",
       "      <td>-1.189393</td>\n",
       "      <td>...</td>\n",
       "      <td>1.615196</td>\n",
       "      <td>0.204363</td>\n",
       "      <td>0.408108</td>\n",
       "      <td>-0.081374</td>\n",
       "      <td>-0.898233</td>\n",
       "      <td>-0.228995</td>\n",
       "      <td>-0.310484</td>\n",
       "      <td>0.327851</td>\n",
       "      <td>-1.297401</td>\n",
       "      <td>-0.891395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 389 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age       Sex  Body_Part  Location  Product_1         0         1  \\\n",
       "0  0.565123 -0.927244  -1.350384 -0.758252  -0.224069  0.811610  0.019274   \n",
       "1 -0.631854  1.078465   0.453370 -0.758252  -0.192996 -1.025957 -1.113281   \n",
       "2 -0.589855 -0.927244  -1.436277  1.728689   2.144190  1.458991 -0.140287   \n",
       "3 -0.085865 -0.927244  -1.436277 -0.447384  -0.240346  0.025051 -1.192750   \n",
       "4 -0.778851 -0.927244  -1.350384  0.485219   0.853892 -0.909808 -0.211408   \n",
       "\n",
       "          2         3         4  ...       374       375       376       377  \\\n",
       "0  0.271284  0.136758  0.071753  ... -1.377549  0.849482  0.391997 -1.091326   \n",
       "1 -0.942938  0.244664 -0.834023  ... -0.673912  0.804057  0.302155 -0.689552   \n",
       "2 -0.975067 -1.404018  0.223374  ...  0.651381  0.207351 -0.125334  1.196148   \n",
       "3  0.343443 -2.602726  1.689154  ... -0.393289 -1.171166  2.125857  1.701152   \n",
       "4  0.480258  1.414003 -1.189393  ...  1.615196  0.204363  0.408108 -0.081374   \n",
       "\n",
       "        378       379       380       381       382       383  \n",
       "0  0.234278 -1.408936  1.093114 -0.670800  0.145674  0.279506  \n",
       "1 -0.387157 -0.493553 -0.488695 -1.462640 -0.049399 -0.936254  \n",
       "2  0.401503 -0.314695 -0.189012 -1.109648  2.615690 -0.022485  \n",
       "3  0.577964 -0.391780 -0.436157 -0.051245  0.130650 -0.411247  \n",
       "4 -0.898233 -0.228995 -0.310484  0.327851 -1.297401 -0.891395  \n",
       "\n",
       "[5 rows x 389 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.47922387, -1.43627734, -1.39333081, -1.35038429, -1.30743776,\n",
       "       -1.26449123, -1.2215447 , -1.17859818, -1.13565165,  0.45336985,\n",
       "        0.49631638,  0.53926291,  0.62515596,  0.66810249,  0.71104902,\n",
       "        0.75399554,  0.79694207,  1.01167471,  1.05462123,  1.18346082,\n",
       "        1.22640734,  1.26935387])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_body_parts = X_test_final['Body_Part'].unique()\n",
    "scaled_body_parts.sort()\n",
    "scaled_body_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30934626 0.88612103\n",
      "0.7667713 0.99066144\n",
      "0.54652345 0.97552365\n",
      "0.566322 0.94858116\n",
      "0.46412307 0.9744108\n",
      "0.6379986 0.9761335\n",
      "0.7210491 0.9890569\n",
      "0.4942655 0.9560213\n",
      "0.29275078 0.9321512\n",
      "0.37983507 0.94591254\n"
     ]
    }
   ],
   "source": [
    "for index, row in X_test_final[:10].iterrows():\n",
    "    prob = []\n",
    "    for body_part in scaled_body_parts:\n",
    "        current_sample = row.copy()\n",
    "        current_sample['Body_Part'] = body_part\n",
    "        # print(current_sample)\n",
    "        prob.append(best_model.predict_proba([current_sample])[0][0])\n",
    "    prob.sort()\n",
    "    print(prob[0], prob[-1]) # min max"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
