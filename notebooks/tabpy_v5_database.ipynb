{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269f3b5c-4817-4322-a446-06678cd7ee2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/eric/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/eric/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/eric/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/eric/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/home/eric/workspace/neiss/.venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d0a723e2fa44ed9317ae508091318a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f66abd2448460f9ffb16e15af55859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d347733ddd0b49aabfd714a67d05fbdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/68.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78fed85005ed45b48308f17648d07d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0827b798500a4fd19c9c5845605f1bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/719 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1157fa27c52a43c29b4375ca189229ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f289c47971b64bb799f834a3e7e96b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c423863265ad4727bf3b6c50dd0cedf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c3e03a45ba4aafb7eb977003299410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73cfa50f7cf644519dab9033780e2e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4400d14cb84dadadb70a3e4e4da5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "with open('X_scaler_10p_v0.pkl', 'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "\n",
    "with open('xgboost_embedding_10p_v0.pkl', 'rb') as file:\n",
    "    best_model = pickle.load(file)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "revision = None  # Replace with the specific revision to ensure reproducibility if the model is updated.\n",
    "model = SentenceTransformer(\"avsolatorio/GIST-small-Embedding-v0\", revision=revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3442568-2779-48c5-96f7-f4aaeac7a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdpt_dict={}\n",
    "bdpt_dict[30]='SHOULDER'\n",
    "bdpt_dict[31]='UPPERTRUNK'\n",
    "bdpt_dict[32]='ELBOW'\n",
    "bdpt_dict[33]='LOWERARM'\n",
    "bdpt_dict[34]='WRIST'\n",
    "bdpt_dict[35]='KNEE'\n",
    "bdpt_dict[36]='LOWERLEG'\n",
    "bdpt_dict[37]='ANKLE'\n",
    "bdpt_dict[38]='PUBICREGION'\n",
    "bdpt_dict[75]='HEAD'\n",
    "bdpt_dict[76]='FACE'\n",
    "bdpt_dict[77]='EYEBALL'\n",
    "bdpt_dict[78]='UPPERTRUNK(OLD)'\n",
    "bdpt_dict[79]='LOWERTRUNK'\n",
    "bdpt_dict[80]='UPPERARM'\n",
    "bdpt_dict[81]='UPPERLEG'\n",
    "bdpt_dict[82]='HAND'\n",
    "bdpt_dict[83]='FOOT'\n",
    "bdpt_dict[88]='MOUTH'\n",
    "bdpt_dict[89]='NECK'\n",
    "bdpt_dict[90]='LOWERARM(OLD)'\n",
    "bdpt_dict[91]='LOWERLEG(OLD)'\n",
    "bdpt_dict[92]='FINGER'\n",
    "bdpt_dict[93]='TOE'\n",
    "bdpt_dict[94]='EAR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913b9255-0020-4636-99bf-207895e58e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(X):\n",
    "\n",
    "    sample_df_single_record=pd.DataFrame(X,columns=['Age', 'Sex','Location','Product_1' ,'activity_at_injury', 'object_involved','injury_mechanism','More_details'])\n",
    "\n",
    "    sample_df_single_record[\"Age\"] = pd.to_numeric(sample_df_single_record[\"Age\"])\n",
    "    sample_df_single_record[\"Sex\"] = pd.to_numeric(sample_df_single_record[\"Sex\"])\n",
    "    sample_df_single_record[\"Location\"] = pd.to_numeric(sample_df_single_record[\"Location\"])\n",
    "    sample_df_single_record[\"Product_1\"] = pd.to_numeric(sample_df_single_record[\"Product_1\"])\n",
    "\n",
    "    sample_df_single_record['Narrative']=sample_df_single_record[\"activity_at_injury\"].astype(str) + ' '+sample_df_single_record[\"injury_mechanism\"].astype(str)+ ' ' + sample_df_single_record[\"object_involved\"].astype(str)+' '+sample_df_single_record[\"More_details\"].astype(str)\n",
    "\n",
    "    Embedding_df=pd.DataFrame(model.encode(sample_df_single_record['Narrative'], convert_to_tensor=True).numpy())\n",
    "    Embedding_df.columns=Embedding_df.columns.astype(str)\n",
    "\n",
    "    sample_df_single_record_2=sample_df_single_record[[\"Age\",\"Sex\",\"Location\",\"Product_1\"]]\n",
    "\n",
    "    return Embedding_df,sample_df_single_record_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04afb55f-13f4-44a8-9f22-99a9dc1dc401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_prediction(bdpt_dict,data_ready,scaler,best_model): #,sematic_distance_bert\n",
    "\n",
    "\n",
    "    prob_out={}\n",
    "\n",
    "    k=0\n",
    "\n",
    "    for i in bdpt_dict:\n",
    "        data_ready.at[0,'Body_Part']=i\n",
    "\n",
    "        X_test_scaled = scaler.transform(data_ready.select_dtypes(include=['number']))\n",
    "        X_test_final=pd.DataFrame(X_test_scaled, columns=data_ready.select_dtypes(include=['number']).columns)\n",
    "        y_prob = best_model.predict_proba(X_test_final)[:, 1][0]\n",
    "        #print(y_prob)\n",
    "        prob_out[str(i)]=y_prob\n",
    "        k+=1\n",
    "\n",
    "    return prob_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47505586-3b9c-471b-864c-eba463cf8286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict_Body_parts_Prob(Age, Sex,Location,Product_1 ,activity_at_injury, object_involved,injury_mechanism,More_details):\n",
    "\n",
    "    coordinates = {\n",
    "        \"Body Part\": [\"SHOULDER\", \"UPPERTRUNK\", \"ELBOW\", \"LOWERARM\", \"WRIST\", \"KNEE\", \"LOWERLEG\", \"ANKLE\", \"PUBICREGION\", \n",
    "                      \"HEAD\", \"FACE\", \"EYEBALL\", \"UPPERTRUNK(OLD)\", \"LOWERTRUNK\", \"UPPERARM\", \"UPPERLEG\", \"HAND\", \"FOOT\", \"MOUTH\",\n",
    "                     \"NECK\", \"LOWERARM(OLD)\", \"LOWERLEG(OLD)\", \"FINGER\", \"TOE\", \"EAR\"],\n",
    "        \"ID\": [30, 31, 32, 33, 34, 35, 36, 37, 38, 75, 76, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 94],\n",
    "        \"X\": [185, 355, 177, 153, 135, 225, 225, 237, 250, 250, 235, 259, 0, 400, 176, 220, 125, 223, 250, 262, 0, 0, 381, 270, 222],\n",
    "        \"Y\": [400, 395, 321, 297, 262, 155, 102, 47, 268, 485, 455, 465, 0, 300, 348, 215, 245, 36, 443, 426, 0, 0, 226, 20, 458]\n",
    "    }\n",
    "    db_insert = pd.DataFrame(coordinates)\n",
    "\n",
    "    X = np.column_stack([Age, Sex,Location,Product_1 ,activity_at_injury, object_involved,injury_mechanism,More_details])\n",
    "    embedding_df,sample_df_single_record_2 = create_df(X)\n",
    "    data = {\"Body_Part\": [25],}\n",
    "    df_body= pd.DataFrame(data)\n",
    "    data_ready = pd.concat([sample_df_single_record_2[['Age','Sex']],df_body,sample_df_single_record_2[['Location','Product_1']], embedding_df], axis=1)\n",
    "    df_output = gen_prediction(bdpt_dict,data_ready,scaler,best_model)\n",
    "\n",
    "    db_insert['Probability'] = db_insert['ID'].map(df_output).fillna(0)\n",
    "\n",
    "    anon_key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Inl5Y2RzcWh1dW5oanp0enZ6d2ZjIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTczMTAyODM5OSwiZXhwIjoyMDQ2NjA0Mzk5fQ.aYVruf5I2zk6-LTgGKz94KSiDt00c4409NqyJagcUSc\"\n",
    "    client = BodyPart(anon_key)\n",
    "    client.delete_all()\n",
    "    client.insert_all(db_insert)\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1309b2bb-64ce-4b93-a7e4-04c58fb5e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BodyPart:\n",
    "    def __init__(self, anon_key: str):\n",
    "        self.base_url = 'https://yycdsqhuunhjztzvzwfc.supabase.co/rest/v1/body_parts'\n",
    "        self.headers = {\n",
    "            'apikey': anon_key,\n",
    "            'Authorization': f'Bearer {anon_key}',\n",
    "            'Content-Type': 'application/json',\n",
    "            'Prefer': 'return=minimal'\n",
    "        }\n",
    "    \n",
    "    def delete_all(self):\n",
    "        response = requests.delete(\n",
    "            f'{self.base_url}?identifier=eq.1',\n",
    "            headers=self.headers\n",
    "        )\n",
    "        return response.status_code < 400\n",
    "    \n",
    "    def insert_all(self, data):\n",
    "        response = requests.post(\n",
    "            self.base_url,\n",
    "            headers=self.headers,\n",
    "            json=data\n",
    "        )\n",
    "        return response.status_code < 400\n",
    "    \n",
    "    def get_all(self):\n",
    "        response = requests.get(\n",
    "            f'{self.base_url}?select=x,y,body_part,probability',\n",
    "            headers=self.headers\n",
    "        )\n",
    "        return response.json() if response.status_code < 400 else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2b8161f-aa58-4a1a-87fd-dbfb0671d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpy.tabpy_tools.client import Client\n",
    "\n",
    "deploy = Client('http://tabpy.ericy.me:9004/')\n",
    "deploy.set_credentials(username='dva023', password='YL8bar-_3.jXGFet')\n",
    "deploy.deploy('tabpy_v2', Predict_Body_parts_Prob, 'tabpy v2 database test', override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e1ed33-a2f2-403c-96e4-8b9a51b99d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
