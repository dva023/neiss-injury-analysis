{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "import spacy\n",
        "import requests\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load the Sentence-BERT model\n",
        "model = SentenceTransformer('paraphrase-MPNet-base-v2')  # This is a lightweight, fast model\n",
        "\n",
        "with open('tfidf_vectorizer.pkl', 'rb') as file:\n",
        "    loaded_vectorizer = pickle.load(file)\n",
        "\n",
        "with open('tfidf_vectorizer_LLM.pkl', 'rb') as file:\n",
        "    loaded_vectorizer_llm = pickle.load(file)\n",
        "\n",
        "with open('X_scaler.pkl', 'rb') as file:\n",
        "    scaler = pickle.load(file)\n",
        "\n",
        "with open('xgboost_tfidf_LLM_v2.pkl', 'rb') as file:\n",
        "    best_model = pickle.load(file)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package punkt to /home/azureuser/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n  warnings.warn(\"Can't initialize NVML\")\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm, trange\n2024-11-07 05:50:51.021328: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1730958651.040947   37884 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1730958651.046763   37884 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-11-07 05:50:51.071639: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730958653811
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730958654011
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bdpt_dict={}\n",
        "bdpt_dict[0]='INTERNAL'\n",
        "bdpt_dict[30]='SHOULDER'\n",
        "bdpt_dict[31]='UPPERTRUNK'\n",
        "bdpt_dict[32]='ELBOW'\n",
        "bdpt_dict[33]='LOWERARM'\n",
        "bdpt_dict[34]='WRIST'\n",
        "bdpt_dict[35]='KNEE'\n",
        "bdpt_dict[36]='LOWERLEG'\n",
        "bdpt_dict[37]='ANKLE'\n",
        "bdpt_dict[38]='PUBICREGION'\n",
        "bdpt_dict[75]='HEAD'\n",
        "bdpt_dict[76]='FACE'\n",
        "bdpt_dict[77]='EYEBALL'\n",
        "bdpt_dict[78]='UPPERTRUNK(OLD)'\n",
        "bdpt_dict[79]='LOWERTRUNK'\n",
        "bdpt_dict[80]='UPPERARM'\n",
        "bdpt_dict[81]='UPPERLEG'\n",
        "bdpt_dict[82]='HAND'\n",
        "bdpt_dict[83]='FOOT'\n",
        "bdpt_dict[84]='25-50% OF BODY'\n",
        "bdpt_dict[85]='ALLPARTSBODY'\n",
        "bdpt_dict[86]='OTHER(OLD)'\n",
        "bdpt_dict[87]='NOTSTATED/UNK'\n",
        "bdpt_dict[88]='MOUTH'\n",
        "bdpt_dict[89]='NECK'\n",
        "bdpt_dict[90]='LOWERARM(OLD)'\n",
        "bdpt_dict[91]='LOWERLEG(OLD)'\n",
        "bdpt_dict[92]='FINGER'\n",
        "bdpt_dict[93]='TOE'\n",
        "bdpt_dict[94]='EAR'"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730958654196
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_df(X):\n",
        "\n",
        "    sample_df_single_record=pd.DataFrame(X,columns=['Age', 'Sex','Location','Product_1' ,'activity_at_injury', 'object_involved','injury_mechanism','More_details'])\n",
        "    \n",
        "    sample_df_single_record[\"Age\"] = pd.to_numeric(sample_df_single_record[\"Age\"])\n",
        "    sample_df_single_record[\"Sex\"] = pd.to_numeric(sample_df_single_record[\"Sex\"])\n",
        "    sample_df_single_record[\"Location\"] = pd.to_numeric(sample_df_single_record[\"Location\"])\n",
        "    sample_df_single_record[\"Product_1\"] = pd.to_numeric(sample_df_single_record[\"Product_1\"])\n",
        "\n",
        "    sample_df_single_record['Narrative_LLM']=sample_df_single_record[\"activity_at_injury\"].astype(str) + ' '+sample_df_single_record[\"injury_mechanism\"].astype(str)+ ' ' + sample_df_single_record[\"object_involved\"].astype(str)\n",
        "    sample_df_single_record['Narrative']=sample_df_single_record[\"More_details\"]\n",
        "\n",
        "    sample_df_single_record_2=sample_df_single_record[[\"Age\",\"Sex\",\"Location\",\"Product_1\"]]\n",
        "\n",
        "    return sample_df_single_record,sample_df_single_record_2"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730958654389
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [token for token in tokens if token.isalpha() and token not in stopwords.words('english')]\n",
        "    tagged_tokens = nltk.pos_tag(tokens)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token, pos='v') for token, pos in tagged_tokens]\n",
        "    return ' '.join(lemmatized_tokens)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730958654554
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_prediction(bdpt_dict,data_ready,scaler,best_model,sematic_distance_bert):\n",
        "\n",
        "\n",
        "    prob_out={}\n",
        "\n",
        "    k=0\n",
        "\n",
        "    for i in bdpt_dict:\n",
        "        data_ready.at[0,'Body_Part']=i\n",
        "        #print(X_test_final)\n",
        "        temp=pd.DataFrame()\n",
        "        #print(len(sematic_distance_bert))\n",
        "        #print(sematic_distance_bert[k])\n",
        "        temp['sematic_distance']=[sematic_distance_bert[k]]\n",
        "        #print(temp)\n",
        "        data_ready_2=pd.concat([temp,data_ready], axis=1)\n",
        "        #print(data_ready_2)\n",
        "\n",
        "        X_test_scaled = scaler.transform(data_ready_2.select_dtypes(include=['number']))\n",
        "        X_test_final=pd.DataFrame(X_test_scaled, columns=data_ready_2.select_dtypes(include=['number']).columns)\n",
        "        y_prob = best_model.predict_proba(X_test_final)[:, 1][0]\n",
        "        #print(y_prob)\n",
        "        prob_out[str(i)]=y_prob\n",
        "        k+=1\n",
        "    \n",
        "    return prob_out"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730958654716
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_similarity(sample_df_single_record,bdpt_dict):\n",
        "\n",
        "\n",
        "    sematic_distance_bert=[]\n",
        "\n",
        "    for key in bdpt_dict:\n",
        "        #print(i)\n",
        "        sentence1 = bdpt_dict[key] #\"cut\"\n",
        "        sentence2 = sample_df_single_record.at[0,'Narrative_LLM'] #\"bike\"\n",
        "\n",
        "        embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
        "        embedding2 = model.encode(sentence2, convert_to_tensor=True)\n",
        "\n",
        "        similarity = util.cos_sim(embedding1, embedding2).item()\n",
        "        sematic_distance_bert.append(similarity)\n",
        "\n",
        "    return sematic_distance_bert"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730958654871
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tfidf_narrative(sample_df_single_record,loaded_vectorizer):\n",
        "\n",
        "    corpus = sample_df_single_record['Narrative'].fillna('')\n",
        "\n",
        "    sample_df_single_record['Processed_Narrative'] = corpus.apply(preprocess_text)\n",
        "    # Use the loaded vectorizer to transform new data\n",
        "    tfidf_matrix = loaded_vectorizer.transform(sample_df_single_record['Processed_Narrative'])\n",
        "\n",
        "    # Convert the TF-IDF matrix to a DataFrame\n",
        "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=loaded_vectorizer.get_feature_names_out())\n",
        "\n",
        "    return tfidf_df"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730958655025
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tfidf_narrative_LLM(sample_df_single_record,loaded_vectorizer_llm):\n",
        "    corpus_LLM = sample_df_single_record['Narrative_LLM'].fillna('')\n",
        "\n",
        "    sample_df_single_record['Processed_Narrative_LLM'] = corpus_LLM.apply(preprocess_text)\n",
        "    # Use the loaded vectorizer to transform new data\n",
        "    tfidf_matrix_LLM = loaded_vectorizer_llm.transform(sample_df_single_record['Processed_Narrative_LLM'])\n",
        "\n",
        "    # Convert the TF-IDF matrix to a DataFrame\n",
        "    tfidf_df_LLM = pd.DataFrame(tfidf_matrix_LLM.toarray(), columns=loaded_vectorizer_llm.get_feature_names_out())\n",
        "    tfidf_df_LLM=tfidf_df_LLM.add_suffix('_LLM')\n",
        "\n",
        "    return tfidf_df_LLM\n",
        "\n",
        "\n",
        "# Concatenate the TF-IDF features with your existing data\n",
        "\n",
        "#data_ready = pd.concat([data_core_sample, tfidf_df_LLM], axis=1)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730958655179
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Predict_Body_parts_Prob(Age, Sex,Location,Product_1 ,activity_at_injury, object_involved,injury_mechanism,More_details):\n",
        "    X = np.column_stack([Age, Sex,Location,Product_1 ,activity_at_injury, object_involved,injury_mechanism,More_details])\n",
        "\n",
        "    sample_df_single_record,sample_df_single_record_2 = create_df(X)\n",
        "\n",
        "    sematic_distance_bert=cal_similarity(sample_df_single_record,bdpt_dict)\n",
        "\n",
        "    tfidf_df = tfidf_narrative(sample_df_single_record,loaded_vectorizer)\n",
        "\n",
        "    tfidf_df_LLM = tfidf_narrative_LLM(sample_df_single_record,loaded_vectorizer_llm)\n",
        "\n",
        "    data = {\"Body_Part\": [25],}\n",
        "    df_body= pd.DataFrame(data)\n",
        "\n",
        "    data_ready = pd.concat([sample_df_single_record_2[['Age','Sex','Location']],df_body,sample_df_single_record_2[['Product_1']], tfidf_df,tfidf_df_LLM], axis=1)\n",
        "    \n",
        "    #print(data_ready)\n",
        "\n",
        "    output = gen_prediction(bdpt_dict,data_ready,scaler,best_model,sematic_distance_bert)\n",
        "    \n",
        "    return output"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730958655335
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Predict_Body_parts_Prob(25, 1,1,3258 ,\"fall walk\", \"bike\",\"\",\"fall from bike when riding\")"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730958636231
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xxxx"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {\n",
        "    \"Age\": [25],\n",
        "    \"Sex\": [0],\n",
        "    \"Location\": [1],\n",
        "    \"Product_1\": [3258],\n",
        "    \"activity_at_injury\": [\"fall walk\"],\n",
        "    \"object_involved\": [\"bike\"],\n",
        "    \"injury_mechanism\": [\" \"],\n",
        "    \"More details\": [\"fall from bike when riding\"]\n",
        "}\n",
        "\n",
        "sample_df_single_record = pd.DataFrame(data)\n",
        "sample_df_single_record"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df_single_record['Narrative_LLM']=sample_df_single_record[\"activity_at_injury\"].astype(str) + ' '+sample_df_single_record[\"injury_mechanism\"].astype(str)+ ' ' + sample_df_single_record[\"object_involved\"].astype(str)\n",
        "sample_df_single_record['Narrative']=sample_df_single_record[\"More details\"]\n",
        "\n",
        "sample_df_single_record_2=sample_df_single_record[[\"Age\",\"Sex\",\"Location\",\"Product_1\"]]\n",
        "sample_df_single_record_2"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730870087179
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the SpaCy model\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "sematic_distance=[]\n",
        "\n",
        "for key in bdpt_dict:\n",
        "\n",
        "    #print(key)\n",
        "    #print(i)\n",
        "    word1 = bdpt_dict[key] #\"cut\"\n",
        "    word2 = sample_df_single_record.at[0,'Narrative_LLM'] #\"bike\"\n",
        "\n",
        "    # SpaCy similarity\n",
        "    doc1 = nlp(word1)\n",
        "    doc2 = nlp(word2)\n",
        "    similarity = doc1.similarity(doc2)\n",
        "    sematic_distance.append(similarity)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730870119997
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730870130090
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730870133053
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"Body_Part\": [25],\n",
        "}\n",
        "df_body= pd.DataFrame(data)\n",
        "data_ready = pd.concat([sample_df_single_record_2[['Age','Sex','Location']],df_body,sample_df_single_record_2[['Product_1']], tfidf_df,tfidf_df_LLM], axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730870137041
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "prob_out"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730870610405
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xxxx\n",
        "def Predict_Body_parts_Prob(Age, Sex, Race,Location,Hispanic, Product_1 ,Alcohol, Drug):\n",
        "    X = np.column_stack([Age, Sex, Race,Location,Hispanic, Product_1 ,Alcohol, Drug])\n",
        "    \n",
        "    return loaded_model.predict_proba(X)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730870245918
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}