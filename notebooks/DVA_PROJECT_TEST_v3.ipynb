{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load your data (replace with your actual data loading)\n",
        "# Assuming your data is in a CSV file named 'data.csv'\n",
        "data = pd.read_csv('azureml://subscriptions/512a781e-d15a-4734-adca-96ec827531cb/resourcegroups/xwang3306-rg/workspaces/DVA_PROJECT/datastores/workspaceblobstore/paths/UI/2024-10-16_040004_UTC/consolidated_cleaned_neiss_2014_2023.csv')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package punkt to /home/azureuser/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1730504158956
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data['Body_Part_Group']=data['Body_Part'].copy()\n",
        "data.loc[((data['Body_Part']==84) | (data['Body_Part']==0)| (data['Body_Part']==85)), 'Body_Part_Group'] = 0 # all internal\n",
        "data.loc[((data['Body_Part']==38) | (data['Body_Part']==79)), 'Body_Part_Group'] = 79 # all internal\n",
        "data.loc[((data['Body_Part']==80) | (data['Body_Part']==30) | (data['Body_Part']==89)), 'Body_Part_Group'] = 30 # all internal\n",
        "data.loc[((data['Body_Part']==32) | (data['Body_Part']==33)), 'Body_Part_Group'] = 33 # all internal\n",
        "data.loc[((data['Body_Part']==88) | (data['Body_Part']==76) | (data['Body_Part']==77)), 'Body_Part_Group'] = 76 # all internal\n",
        "data.loc[((data['Body_Part']==81) | (data['Body_Part']==35)), 'Body_Part_Group'] = 35 # all internal\n",
        "data.loc[((data['Body_Part']==87)| (data['Body_Part']==94)), 'Body_Part_Group'] = np.nan # all internal\n",
        "data.loc[((data['Body_Part']==93) | (data['Body_Part']==83)| (data['Body_Part']==37)), 'Body_Part_Group'] = 37 # all internal\n",
        "data=data[data['Body_Part_Group'].notna()]"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730504160020
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Body_Part_Group'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "75.0    606221\n76.0    425448\n37.0    401233\n79.0    304586\n92.0    285292\n30.0    238774\n35.0    225049\n33.0    208119\n31.0    197923\n82.0    154695\n0.0     131460\n36.0    127365\n34.0    115960\nName: Body_Part_Group, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730504160345
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_after_dx(narrative):\n",
        "  if isinstance(narrative, str):\n",
        "    parts = narrative.split(\"DX\", 1)\n",
        "    if len(parts) > 1:\n",
        "      return parts[0]\n",
        "    else:\n",
        "      return narrative  # No \"DX:\" found, return the original string\n",
        "  else:\n",
        "    return narrative  # Not a string, return as is\n",
        "\n",
        "\n",
        "data['Narrative'] = data['Narrative'].apply(remove_after_dx)\n",
        "data['Narrative'] = data['Narrative'].str.replace('YOM', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('YOF', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('YR', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('OLD', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('MALE', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('FEMALE', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace(' YO ', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('ACCIDENTALLY','')\n",
        "data['Narrative'] = data['Narrative'].str.replace('AGO', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('TODAY', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('YESTERDAY', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('PATIENT', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace(' PT ', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('INJURY', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('REPORT', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('HURT', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('INJ', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('FELL', 'FALL')\n",
        "data['Narrative'] = data['Narrative'].str.replace('INJURE', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace(' ED', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace(' RT ', '')\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730504228341
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "core_col=['Age', 'Sex', 'Race','Location','Hispanic', 'Body_Part_Group','Product_1' ,'Alcohol', 'Drug','Narrative']\n",
        "data_core=data[core_col]\n",
        "data_core_sample=data_core.sample(frac=0.1).reset_index(drop=True)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730504228685
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "\n",
        "corpus = data_core_sample['Narrative'].fillna('')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [token for token in tokens if token.isalpha() and token not in stopwords.words('english')]\n",
        "    tagged_tokens = nltk.pos_tag(tokens)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token, pos='v') for token, pos in tagged_tokens]\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "data_core_sample['Processed_Narrative'] = corpus.apply(preprocess_text)\n",
        "\n",
        "# Create a TfidfVectorizer object\n",
        "vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
        "\n",
        "# Fit and transform the processed text\n",
        "tfidf_matrix = vectorizer.fit_transform(data_core_sample['Processed_Narrative'])\n",
        "\n",
        "# Convert the TF-IDF matrix to a DataFrame\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Concatenate the TF-IDF features with your existing data\n",
        "data_ready = pd.concat([data_core_sample, tfidf_df], axis=1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package punkt_tab to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n[nltk_data]       date!\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730504693013
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features (X) and target variable (y)\n",
        "X = data_ready.drop(['Body_Part_Group','Narrative','Processed_Narrative'], axis=1)  # ,'Processed_Narrative'] Replace 'target_variable' with your target column name\n",
        "y = data_ready['Body_Part_Group']\n",
        "\n",
        "# Encode target variable if it's categorical\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a scaler for numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.select_dtypes(include=['number']))\n",
        "X_test_scaled = scaler.transform(X_test.select_dtypes(include=['number']))\n",
        "\n",
        "# Convert scaled features back to DataFrame\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.select_dtypes(include=['number']).columns)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.select_dtypes(include=['number']).columns)\n",
        "\n",
        "# Combine scaled numerical features with categorical features\n",
        "X_train_final = X_train_scaled_df.copy()\n",
        "X_test_final = X_test_scaled_df.copy()\n",
        "\n",
        "\n",
        "# Define models and their parameter grids for hyperparameter tuning\n",
        "models = {\n",
        "    'KNN': (KNeighborsClassifier(), {'knn__n_neighbors': [3, 5, 7]}),\n",
        "    'Random_Forest': (RandomForestClassifier(), {'random_forest__n_estimators': [100, 200], 'random_forest__max_depth': [4, 8]}),\n",
        "   # 'Lasso': (Lasso(), {'lasso__alpha': [0.1, 1.0]}),\n",
        "    #'SVM': (SVC(probability=True), {'svm__C': [0.1, 1.0], 'svm__kernel': ['linear', 'rbf']}),\n",
        "    'XGBoost': (XGBClassifier(objective='multi:softmax', num_class=len(le.classes_)),\n",
        "               {'xgboost__learning_rate': [0.1, 0.01], 'xgboost__max_depth': [3, 5]})\n",
        "}\n",
        "\n",
        "# Create an ensemble of models\n",
        "ensemble_predictions = []\n",
        "for model_name, (model, param_grid) in models.items():\n",
        "    print(f\"Training {model_name}...\")\n",
        "\n",
        "    # Create a pipeline for preprocessing and model training\n",
        "    pipeline = Pipeline([\n",
        "        (model_name.lower(), model)\n",
        "    ])\n",
        "\n",
        "    # Perform hyperparameter tuning using GridSearchCV\n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy')\n",
        "    grid_search.fit(X_train_final, y_train)\n",
        "\n",
        "    # Get the best model from the grid search\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = best_model.predict(X_test_final)\n",
        "    ensemble_predictions.append(y_pred)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{model_name} Accuracy:\", accuracy)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Implement your ensemble method (e.g., voting)\n",
        "# For example, you can use a simple majority vote:\n",
        "from scipy.stats import mode\n",
        "\n",
        "ensemble_predictions = np.array(ensemble_predictions)\n",
        "ensemble_pred_final = mode(ensemble_predictions, axis=0)[0].flatten()\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "ensemble_accuracy = accuracy_score(y_test, ensemble_pred_final)\n",
        "print(\"Ensemble Accuracy:\", ensemble_accuracy)\n",
        "print(classification_report(y_test, ensemble_pred_final))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training KNN...\nKNN Accuracy: 0.6171997136303201\n              precision    recall  f1-score   support\n\n           0       0.44      0.61      0.51      2711\n           1       0.52      0.54      0.53      4865\n           2       0.42      0.44      0.43      4048\n           3       0.49      0.52      0.51      4273\n           4       0.70      0.56      0.62      2320\n           5       0.64      0.56      0.60      4525\n           6       0.58      0.44      0.50      2548\n           7       0.76      0.78      0.77      7918\n           8       0.61      0.71      0.65     11943\n           9       0.63      0.55      0.58      8393\n          10       0.58      0.54      0.56      6123\n          11       0.71      0.67      0.69      3079\n          12       0.85      0.79      0.82      5697\n\n    accuracy                           0.62     68443\n   macro avg       0.61      0.59      0.60     68443\nweighted avg       0.62      0.62      0.62     68443\n\nTraining Random_Forest...\nRandom_Forest Accuracy: 0.6162061861695133\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00      2711\n           1       0.90      0.44      0.59      4865\n           2       0.90      0.31      0.47      4048\n           3       0.72      0.47      0.57      4273\n           4       0.89      0.56      0.69      2320\n           5       0.90      0.58      0.71      4525\n           6       0.75      0.48      0.59      2548\n           7       0.89      0.79      0.84      7918\n           8       0.38      0.91      0.54     11943\n           9       0.56      0.55      0.56      8393\n          10       0.72      0.47      0.57      6123\n          11       0.78      0.71      0.74      3079\n          12       0.91      0.84      0.87      5697\n\n    accuracy                           0.62     68443\n   macro avg       0.71      0.55      0.59     68443\nweighted avg       0.69      0.62      0.61     68443\n\nTraining XGBoost...\n[23:59:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:03:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:06:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:10:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:16:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:22:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:28:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:32:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:35:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:39:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:45:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:51:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[00:57:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nXGBoost Accuracy: 0.6787399734085298\n              precision    recall  f1-score   support\n\n           0       0.54      0.63      0.58      2711\n           1       0.84      0.50      0.63      4865\n           2       0.61      0.45      0.52      4048\n           3       0.61      0.58      0.60      4273\n           4       0.87      0.59      0.70      2320\n           5       0.91      0.59      0.71      4525\n           6       0.74      0.50      0.60      2548\n           7       0.83      0.83      0.83      7918\n           8       0.61      0.80      0.69     11943\n           9       0.62      0.67      0.64      8393\n          10       0.47      0.63      0.54      6123\n          11       0.75      0.76      0.75      3079\n          12       0.92      0.84      0.88      5697\n\n    accuracy                           0.68     68443\n   macro avg       0.72      0.64      0.67     68443\nweighted avg       0.70      0.68      0.68     68443\n\nEnsemble Accuracy: 0.6682348815802931\n              precision    recall  f1-score   support\n\n           0       0.48      0.64      0.55      2711\n           1       0.65      0.52      0.58      4865\n           2       0.53      0.45      0.48      4048\n           3       0.59      0.57      0.58      4273\n           4       0.83      0.59      0.69      2320\n           5       0.81      0.60      0.69      4525\n           6       0.69      0.50      0.58      2548\n           7       0.82      0.83      0.82      7918\n           8       0.55      0.83      0.66     11943\n           9       0.67      0.61      0.64      8393\n          10       0.68      0.53      0.60      6123\n          11       0.78      0.74      0.76      3079\n          12       0.92      0.84      0.88      5697\n\n    accuracy                           0.67     68443\n   macro avg       0.69      0.63      0.65     68443\nweighted avg       0.69      0.67      0.67     68443\n\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/tmp/ipykernel_30399/3495394286.py:67: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n  ensemble_pred_final = mode(ensemble_predictions, axis=0)[0].flatten()\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730509585318
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xxx"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'xxx' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mxxx\u001b[49m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xxx' is not defined"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730509585767
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features (X) and target variable (y)\n",
        "X = data_ready.drop(['Body_Part_Group','Narrative','Processed_Narrative'], axis=1)  # Replace 'target_variable' with your target column name\n",
        "y = data_ready['Body_Part_Group']\n",
        "\n",
        "# Encode target variable if it's categorical\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "model = XGBClassifier(objective='multi:softmax', num_class=len(le.classes_),\n",
        "                     # Add other hyperparameters as needed (e.g., learning_rate, max_depth)\n",
        "                     )\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print classification report for detailed metrics\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730509586942
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('xgb_toy.pkl', 'rb') as f:  # Replace 'your_model_file.pkl' with the actual file name\n",
        "    loaded_model = pickle.load(f)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730509586970
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Predict_Body_parts_Prob(Age, Sex, Race,Location,Hispanic, Product_1 ,Alcohol, Drug):\n",
        "    X = np.column_stack([Age, Sex, Race,Location,Hispanic, Product_1 ,Alcohol, Drug])\n",
        "    \n",
        "    return loaded_model.predict_proba(X)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730509586995
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Predict_Body_parts_Prob(20,1,0,1,0,1,0,0)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730509587018
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba = loaded_model.predict_proba(X_test)\n",
        "y_pred_proba"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730509587039
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model to a file\n",
        "pickle.dump(model, open(\"xgb_toy.pkl\", \"wb\"))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730509587067
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = le.classes_\n",
        "\n",
        "# Print the class labels\n",
        "print(\"Class Labels:\", class_labels)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730509587094
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Cloud"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "part=[75,76,79,92,31,37,35,82,83,30,36,33,34]  "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730509587198
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in part:\n",
        "    data_filtered=data[data['Body_Part']==i]\n",
        "    # Assuming you want to create a word cloud from the 'Narrative' column\n",
        "    text = \" \".join(review for review in data_filtered.Narrative.astype(str))\n",
        "\n",
        "    # Generate the word cloud\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "    # Display the generated image:\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730509587219
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(2014,2024):\n",
        "    data_filtered=data[data['Year']==i]\n",
        "    # Assuming you want to create a word cloud from the 'Narrative' column\n",
        "    text = \" \".join(review for review in data_filtered.Narrative.astype(str))\n",
        "\n",
        "    # Generate the word cloud\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "    # Display the generated image:\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730509587246
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "# Assuming you want to create a word cloud from the 'Narrative' column\n",
        "text = \" \".join(review for review in data_filtered.Narrative.astype(str))\n",
        "\n",
        "# Generate the word cloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "# Display the generated image:\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730509587272
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}