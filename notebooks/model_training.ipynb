{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1731120966160
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/eric/miniconda3/envs/neiss/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /home/eric/miniconda3/envs/neiss/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/eric/miniconda3/envs/neiss/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/eric/miniconda3/envs/neiss/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /home/eric/miniconda3/envs/neiss/lib/python3.12/site-packages (from nltk) (4.66.6)\n",
      "Requirement already satisfied: xgboost in /home/eric/miniconda3/envs/neiss/lib/python3.12/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in /home/eric/miniconda3/envs/neiss/lib/python3.12/site-packages (from xgboost) (2.0.2)\n",
      "Requirement already satisfied: scipy in /home/eric/miniconda3/envs/neiss/lib/python3.12/site-packages (from xgboost) (1.14.1)\n",
      "Requirement already satisfied: imblearn in /home/eric/miniconda3/envs/neiss/lib/python3.12/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /home/eric/miniconda3/envs/neiss/lib/python3.12/site-packages (from imblearn) (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/eric/miniconda3/envs/neiss/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/eric/miniconda3/envs/neiss/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /home/eric/miniconda3/envs/neiss/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/eric/miniconda3/envs/neiss/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/eric/miniconda3/envs/neiss/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "!pip install nltk\n",
    "!pip install xgboost\n",
    "!pip install imblearn\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "#from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "#embedding_2=pd.read_csv('../xwang3306/aliba_embedding_10p.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/eric/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/eric/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/eric/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/eric/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_10p (352052, 28)\n",
      "embedding (352052, 385)\n",
      "   CPSC_Case_Number         0         1         2         3         4  \\\n",
      "0         221032332 -0.030642 -0.022758  0.049370 -0.026157  0.004854   \n",
      "1         181109464 -0.017625 -0.034500  0.065491  0.020524  0.021781   \n",
      "2         210103105 -0.047855 -0.018055  0.025419 -0.006466 -0.065742   \n",
      "3         161157997 -0.030252 -0.054146  0.042925  0.049154 -0.037071   \n",
      "4         181107411 -0.018278 -0.007797  0.042058 -0.069821 -0.010598   \n",
      "5         200134239 -0.011073  0.017136  0.011212 -0.013588 -0.007029   \n",
      "6         140951498 -0.025121  0.012701  0.044701 -0.061955 -0.004564   \n",
      "7         221017396 -0.032237 -0.021063  0.026084 -0.042346 -0.011767   \n",
      "8         200645623 -0.006542 -0.033106  0.048509 -0.078780  0.000256   \n",
      "9         141040420  0.019674 -0.015743  0.015878 -0.029989  0.005483   \n",
      "\n",
      "          5         6         7         8  ...       374       375       376  \\\n",
      "0  0.001444  0.116881  0.035861  0.000974  ...  0.014122 -0.030197 -0.002454   \n",
      "1  0.042113  0.060077  0.042478 -0.014973  ...  0.024239 -0.000142  0.007269   \n",
      "2  0.076648  0.034142  0.024870 -0.019512  ...  0.040865  0.019481  0.005293   \n",
      "3  0.039133  0.057640 -0.004184 -0.040747  ...  0.013746 -0.022505 -0.026468   \n",
      "4 -0.023407  0.075656  0.022712  0.009543  ...  0.023318 -0.049932  0.014847   \n",
      "5  0.040133  0.086129  0.014111  0.011250  ...  0.026607 -0.051627  0.009689   \n",
      "6  0.058160  0.083629  0.035080  0.045997  ...  0.069417  0.006998 -0.016011   \n",
      "7  0.047811  0.052396  0.093629 -0.003813  ...  0.016179 -0.031867 -0.007946   \n",
      "8  0.044473  0.034837  0.097354  0.007700  ...  0.057451 -0.029053 -0.016805   \n",
      "9  0.034219  0.048066  0.047623  0.004988  ...  0.000669  0.020707 -0.023070   \n",
      "\n",
      "        377       378       379       380       381       382       383  \n",
      "0  0.026395 -0.048185 -0.001542 -0.017451 -0.050880 -0.008124  0.030714  \n",
      "1 -0.015545 -0.040856 -0.042023 -0.050380  0.008760 -0.002266  0.043031  \n",
      "2 -0.059021 -0.047235  0.024601 -0.067565 -0.025657 -0.013521 -0.015571  \n",
      "3 -0.053529 -0.033781  0.023896 -0.037096 -0.075717  0.052297  0.016317  \n",
      "4  0.037483  0.025916  0.035806 -0.044568  0.014808 -0.021472  0.001994  \n",
      "5  0.018880 -0.001498 -0.021843 -0.073475  0.022928 -0.010549  0.009171  \n",
      "6 -0.011223 -0.006756  0.047259 -0.013498 -0.033564  0.013709  0.049572  \n",
      "7 -0.036613 -0.030827  0.035943 -0.010132 -0.029518 -0.000366  0.040291  \n",
      "8  0.008903 -0.002621  0.016930 -0.115614 -0.006699 -0.102164  0.057578  \n",
      "9  0.032140 -0.013655  0.035791 -0.008253 -0.096477  0.032906  0.039108  \n",
      "\n",
      "[10 rows x 385 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load your data (replace with your actual data loading)\n",
    "# Assuming your data is in a CSV file named 'data.csv'\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data_size = '10p'\n",
    "# data_size = 'full'\n",
    "version = 'v0'\n",
    "\n",
    "data_10P = pd.read_csv('../data/neiss_10p_sample.csv') if data_size == '10p' else pd.read_csv('../data/consolidated_cleaned_neiss_2014_2023.csv')\n",
    "\n",
    "# data_10P = pd.read_csv('../data/neiss_10p_sample.csv')\n",
    "if data_size == '10p':\n",
    "    data_10P = data_10P.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "print(\"data_10p\", data_10P.shape)\n",
    "\n",
    "embedding=pd.read_csv(f'../data/gist_embedding_{data_size}_{version}.csv')\n",
    "print(\"embedding\", embedding.shape)\n",
    "# print(\"new_columns\", new_columns.shape)\n",
    "print(embedding.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1731120993237
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352052, 391)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPSC_Case_Number</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Location</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221032332</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1205</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.030642</td>\n",
       "      <td>-0.022758</td>\n",
       "      <td>0.049370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014122</td>\n",
       "      <td>-0.030197</td>\n",
       "      <td>-0.002454</td>\n",
       "      <td>0.026395</td>\n",
       "      <td>-0.048185</td>\n",
       "      <td>-0.001542</td>\n",
       "      <td>-0.017451</td>\n",
       "      <td>-0.050880</td>\n",
       "      <td>-0.008124</td>\n",
       "      <td>0.030714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181109464</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>1141</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.017625</td>\n",
       "      <td>-0.034500</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024239</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>0.007269</td>\n",
       "      <td>-0.015545</td>\n",
       "      <td>-0.040856</td>\n",
       "      <td>-0.042023</td>\n",
       "      <td>-0.050380</td>\n",
       "      <td>0.008760</td>\n",
       "      <td>-0.002266</td>\n",
       "      <td>0.043031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210103105</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>5033</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.047855</td>\n",
       "      <td>-0.018055</td>\n",
       "      <td>0.025419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040865</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>-0.059021</td>\n",
       "      <td>-0.047235</td>\n",
       "      <td>0.024601</td>\n",
       "      <td>-0.067565</td>\n",
       "      <td>-0.025657</td>\n",
       "      <td>-0.013521</td>\n",
       "      <td>-0.015571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161157997</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>1842</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.030252</td>\n",
       "      <td>-0.054146</td>\n",
       "      <td>0.042925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>-0.022505</td>\n",
       "      <td>-0.026468</td>\n",
       "      <td>-0.053529</td>\n",
       "      <td>-0.033781</td>\n",
       "      <td>0.023896</td>\n",
       "      <td>-0.037096</td>\n",
       "      <td>-0.075717</td>\n",
       "      <td>0.052297</td>\n",
       "      <td>0.016317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181107411</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>5020</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.018278</td>\n",
       "      <td>-0.007797</td>\n",
       "      <td>0.042058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023318</td>\n",
       "      <td>-0.049932</td>\n",
       "      <td>0.014847</td>\n",
       "      <td>0.037483</td>\n",
       "      <td>0.025916</td>\n",
       "      <td>0.035806</td>\n",
       "      <td>-0.044568</td>\n",
       "      <td>0.014808</td>\n",
       "      <td>-0.021472</td>\n",
       "      <td>0.001994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200134239</td>\n",
       "      <td>207</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>1682</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.011073</td>\n",
       "      <td>0.017136</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026607</td>\n",
       "      <td>-0.051627</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.018880</td>\n",
       "      <td>-0.001498</td>\n",
       "      <td>-0.021843</td>\n",
       "      <td>-0.073475</td>\n",
       "      <td>0.022928</td>\n",
       "      <td>-0.010549</td>\n",
       "      <td>0.009171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>140951498</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>1200</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.025121</td>\n",
       "      <td>0.012701</td>\n",
       "      <td>0.044701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.006998</td>\n",
       "      <td>-0.016011</td>\n",
       "      <td>-0.011223</td>\n",
       "      <td>-0.006756</td>\n",
       "      <td>0.047259</td>\n",
       "      <td>-0.013498</td>\n",
       "      <td>-0.033564</td>\n",
       "      <td>0.013709</td>\n",
       "      <td>0.049572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>221017396</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>557</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.032237</td>\n",
       "      <td>-0.021063</td>\n",
       "      <td>0.026084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016179</td>\n",
       "      <td>-0.031867</td>\n",
       "      <td>-0.007946</td>\n",
       "      <td>-0.036613</td>\n",
       "      <td>-0.030827</td>\n",
       "      <td>0.035943</td>\n",
       "      <td>-0.010132</td>\n",
       "      <td>-0.029518</td>\n",
       "      <td>-0.000366</td>\n",
       "      <td>0.040291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200645623</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1333</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.006542</td>\n",
       "      <td>-0.033106</td>\n",
       "      <td>0.048509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057451</td>\n",
       "      <td>-0.029053</td>\n",
       "      <td>-0.016805</td>\n",
       "      <td>0.008903</td>\n",
       "      <td>-0.002621</td>\n",
       "      <td>0.016930</td>\n",
       "      <td>-0.115614</td>\n",
       "      <td>-0.006699</td>\n",
       "      <td>-0.102164</td>\n",
       "      <td>0.057578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>141040420</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>9</td>\n",
       "      <td>1266</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019674</td>\n",
       "      <td>-0.015743</td>\n",
       "      <td>0.015878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.020707</td>\n",
       "      <td>-0.023070</td>\n",
       "      <td>0.032140</td>\n",
       "      <td>-0.013655</td>\n",
       "      <td>0.035791</td>\n",
       "      <td>-0.008253</td>\n",
       "      <td>-0.096477</td>\n",
       "      <td>0.032906</td>\n",
       "      <td>0.039108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CPSC_Case_Number  Age  Sex  Body_Part  Location  Product_1  Disposition  \\\n",
       "0         221032332   14    1         34         0       1205            1   \n",
       "1         181109464   28    1         79         1       1141            1   \n",
       "2         210103105   35    1         30         9       5033            1   \n",
       "3         161157997  214    2         76         0       1842            1   \n",
       "4         181107411    4    1         92         1       5020            1   \n",
       "5         200134239  207    1         82         1       1682            1   \n",
       "6         140951498   12    1         82         8       1200            1   \n",
       "7         221017396   44    2         79         0        557            1   \n",
       "8         200645623   28    1         30         0       1333            1   \n",
       "9         141040420   16    2         79         9       1266            1   \n",
       "\n",
       "          0         1         2  ...       374       375       376       377  \\\n",
       "0 -0.030642 -0.022758  0.049370  ...  0.014122 -0.030197 -0.002454  0.026395   \n",
       "1 -0.017625 -0.034500  0.065491  ...  0.024239 -0.000142  0.007269 -0.015545   \n",
       "2 -0.047855 -0.018055  0.025419  ...  0.040865  0.019481  0.005293 -0.059021   \n",
       "3 -0.030252 -0.054146  0.042925  ...  0.013746 -0.022505 -0.026468 -0.053529   \n",
       "4 -0.018278 -0.007797  0.042058  ...  0.023318 -0.049932  0.014847  0.037483   \n",
       "5 -0.011073  0.017136  0.011212  ...  0.026607 -0.051627  0.009689  0.018880   \n",
       "6 -0.025121  0.012701  0.044701  ...  0.069417  0.006998 -0.016011 -0.011223   \n",
       "7 -0.032237 -0.021063  0.026084  ...  0.016179 -0.031867 -0.007946 -0.036613   \n",
       "8 -0.006542 -0.033106  0.048509  ...  0.057451 -0.029053 -0.016805  0.008903   \n",
       "9  0.019674 -0.015743  0.015878  ...  0.000669  0.020707 -0.023070  0.032140   \n",
       "\n",
       "        378       379       380       381       382       383  \n",
       "0 -0.048185 -0.001542 -0.017451 -0.050880 -0.008124  0.030714  \n",
       "1 -0.040856 -0.042023 -0.050380  0.008760 -0.002266  0.043031  \n",
       "2 -0.047235  0.024601 -0.067565 -0.025657 -0.013521 -0.015571  \n",
       "3 -0.033781  0.023896 -0.037096 -0.075717  0.052297  0.016317  \n",
       "4  0.025916  0.035806 -0.044568  0.014808 -0.021472  0.001994  \n",
       "5 -0.001498 -0.021843 -0.073475  0.022928 -0.010549  0.009171  \n",
       "6 -0.006756  0.047259 -0.013498 -0.033564  0.013709  0.049572  \n",
       "7 -0.030827  0.035943 -0.010132 -0.029518 -0.000366  0.040291  \n",
       "8 -0.002621  0.016930 -0.115614 -0.006699 -0.102164  0.057578  \n",
       "9 -0.013655  0.035791 -0.008253 -0.096477  0.032906  0.039108  \n",
       "\n",
       "[10 rows x 391 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data=data_10P.merge(new_columns,how='inner',on='CPSC_Case_Number').merge(embedding,how='inner',on='CPSC_Case_Number').reset_index(drop=True)\n",
    "data_10P = data_10P[['CPSC_Case_Number', 'Age', 'Sex', 'Body_Part', 'Location', 'Product_1', 'Disposition']]\n",
    "data=data_10P.merge(embedding,how='inner',on='CPSC_Case_Number').reset_index(drop=True)\n",
    "del data_10P\n",
    "del embedding\n",
    "# data_10P.head(10)\n",
    "# embedding.head(10)\n",
    "print(data.shape)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CPSC_Case_Number', 'Age', 'Sex', 'Body_Part', 'Location', 'Product_1', 'Disposition', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383']\n"
     ]
    }
   ],
   "source": [
    "print(list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1731121003728
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data['Disposition_recode']=np.nan\n",
    "data.loc[((data['Disposition']==1)), 'Disposition_recode'] = 0\n",
    "data.loc[((data['Disposition']==2)), 'Disposition_recode'] = 1\n",
    "data.loc[((data['Disposition']==4)), 'Disposition_recode'] = 2\n",
    "data.loc[((data['Disposition']==5)), 'Disposition_recode'] = 3\n",
    "data.loc[((data['Disposition']==8)), 'Disposition_recode'] = 4\n",
    "data=data[data['Disposition_recode'].notna()]\n",
    "\n",
    "data['Disposition_recode_2']=0\n",
    "data.loc[((data['Disposition_recode']>0)), 'Disposition_recode_2'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disposition_recode_2\n",
       "0    296228\n",
       "1     32874\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data[(data['Body_Part']!=0) & (data['Body_Part']!=84) & (data['Body_Part']!=85) & (data['Body_Part']!=86) & (data['Body_Part']!=87)]\n",
    "data['Disposition_recode'].value_counts()\n",
    "data['Disposition_recode_2'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1731121014315
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "bdpt_dict={}\n",
    "bdpt_dict[0]='INTERNAL'\n",
    "bdpt_dict[30]='SHOULDER'\n",
    "bdpt_dict[31]='UPPERTRUNK'\n",
    "bdpt_dict[32]='ELBOW'\n",
    "bdpt_dict[33]='LOWERARM'\n",
    "bdpt_dict[34]='WRIST'\n",
    "bdpt_dict[35]='KNEE'\n",
    "bdpt_dict[36]='LOWERLEG'\n",
    "bdpt_dict[37]='ANKLE'\n",
    "bdpt_dict[38]='PUBICREGION'\n",
    "bdpt_dict[75]='HEAD'\n",
    "bdpt_dict[76]='FACE'\n",
    "bdpt_dict[77]='EYEBALL'\n",
    "bdpt_dict[78]='UPPERTRUNK(OLD)'\n",
    "bdpt_dict[79]='LOWERTRUNK'\n",
    "bdpt_dict[80]='UPPERARM'\n",
    "bdpt_dict[81]='UPPERLEG'\n",
    "bdpt_dict[82]='HAND'\n",
    "bdpt_dict[83]='FOOT'\n",
    "bdpt_dict[84]='25-50% OF BODY'\n",
    "bdpt_dict[85]='ALLPARTSBODY'\n",
    "bdpt_dict[86]='OTHER(OLD)'\n",
    "bdpt_dict[87]='NOTSTATED/UNK'\n",
    "bdpt_dict[88]='MOUTH'\n",
    "bdpt_dict[89]='NECK'\n",
    "bdpt_dict[90]='LOWERARM(OLD)'\n",
    "bdpt_dict[91]='LOWERLEG(OLD)'\n",
    "bdpt_dict[92]='FINGER'\n",
    "bdpt_dict[93]='TOE'\n",
    "bdpt_dict[94]='EAR'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1731121020538
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "data['body_string']=data['Body_Part'].map(bdpt_dict)\n",
    "# data['Narrative_LLM']=data[\"activity_at_injury\"].astype(str) + ' '+data[\"injury_mechanism\"].astype(str)+ ' ' + data[\"object_involved\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1731114277211
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (329102, 394)\n",
      "Train set size: 263282 rows\n",
      "Test set size: 65820 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['CPSC_Case_Number', 'Age', 'Sex', 'Body_Part', 'Location', 'Product_1',\n",
       "       'Disposition', '0', '1', '2',\n",
       "       ...\n",
       "       '377', '378', '379', '380', '381', '382', '383', 'Disposition_recode',\n",
       "       'Disposition_recode_2', 'body_string'],\n",
       "      dtype='object', length=394)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "total_rows, n_columns = data.shape\n",
    "\n",
    "test_size = int(total_rows * 0.2)\n",
    "train_size = total_rows - test_size\n",
    "\n",
    "print(f\"Original dataset shape: ({total_rows}, {n_columns})\")\n",
    "print(f\"Train set size: {train_size} rows\")\n",
    "print(f\"Test set size: {test_size} rows\")\n",
    "data_sample = data.sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "\n",
    "data_ready = data_sample.tail(train_size).reset_index(drop=True)\n",
    "data_ready_test = data_sample.head(test_size).reset_index(drop=True)\n",
    "del data\n",
    "\n",
    "# data_test=data_core.head(21000).reset_index(drop=True)\n",
    "# data_fit=data_core.tail(191347).reset_index(drop=True)\n",
    "# df_bad=data_fit[data_fit['Disposition_recode_2']==1]\n",
    "# df_good=data_fit[data_fit['Disposition_recode_2']==0]\n",
    "# data_good_sample=df_good.sample(frac=0.2,random_state=42).reset_index(drop=True)\n",
    "# data_bad_sample=df_bad.sample(frac=0.8,random_state=42).reset_index(drop=True)\n",
    "# data_core_sample=pd.concat([data_good_sample,data_bad_sample]).reset_index(drop=True)\n",
    "# data_core_sample=data_core_sample.sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "# data_core_sample.head()\n",
    "\n",
    "# data_ready = data_core_sample\n",
    "# data_ready_test = data_test\n",
    "data_ready.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1731114704628
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "drop_list=[\n",
    " 'CPSC_Case_Number',\n",
    " 'Disposition',\n",
    " 'Disposition_recode',\n",
    " 'Disposition_recode_2',\n",
    " 'body_string',\n",
    "]\n",
    "\n",
    "drop_list_test = drop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Sex', 'Body_Part', 'Location', 'Product_1', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383']\n"
     ]
    }
   ],
   "source": [
    "X = data_ready.drop(drop_list, axis=1) \n",
    "y = data_ready['Disposition_recode_2']\n",
    "\n",
    "print(list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1731115388172
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 82\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Perform hyperparameter tuning using GridSearchCV with AUC score\u001b[39;00m\n\u001b[1;32m     81\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m,n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_final\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Get the best model from the grid search\u001b[39;00m\n\u001b[1;32m     85\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/miniconda3/envs/neiss/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neiss/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/neiss/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neiss/lib/python3.12/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/neiss/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neiss/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neiss/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/neiss/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, roc_auc_score\n",
    "from scipy.stats import mode\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data_ready.drop(drop_list, axis=1) \n",
    "y = data_ready['Disposition_recode_2']\n",
    "\n",
    "# Encode target variable if it's categorical\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, _, y_train, _ = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test=data_ready_test.drop(drop_list_test, axis=1)\n",
    "y_test=data_ready_test['Disposition_recode_2']\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# Create a scaler for numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.select_dtypes(include=['number']))\n",
    "\n",
    "with open(f'X_scaler_{data_size}_{version}.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test.select_dtypes(include=['number']))\n",
    "\n",
    "# Convert scaled features back to DataFrame\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.select_dtypes(include=['number']).columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.select_dtypes(include=['number']).columns)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_scaled_df, y_train)\n",
    "\n",
    "# Combine scaled numerical features with categorical features\n",
    "X_train_final = X_resampled.copy()\n",
    "X_test_final = X_test_scaled_df.copy()\n",
    "y_train_final=y_resampled.copy()\n",
    "\n",
    "\n",
    "# Define models and their parameter grids for hyperparameter tuning\n",
    "models = {\n",
    "    #'KNN': (KNeighborsClassifier(), {'knn__n_neighbors': [3, 5, 7]}),\n",
    "    #'Random_Forest': (RandomForestClassifier(), {'random_forest__n_estimators': [100, 200], 'random_forest__max_depth': [4, 8]}),\n",
    "    'XGBoost': (XGBClassifier(objective='binary:logistic'), \n",
    "           {'xgboost__learning_rate': [0.1, 0.01, 0.001],            # Step size shrinkage to prevent overfitting\n",
    "            'xgboost__max_depth': [3, 5, 7],                         # Maximum depth of each tree\n",
    "            #'xgboost__n_estimators': [100, 200, 300],                # Number of boosting rounds\n",
    "            #'xgboost__min_child_weight': [1, 3, 5],                  # Minimum sum of instance weight needed in a child\n",
    "            #'xgboost__subsample': [0.6, 0.8,0.9],                   # Subsample ratio of the training instances\n",
    "            #'xgboost__colsample_bytree': [0.6, 0.8, 0.9],            # Subsample ratio of columns when constructing each tree\n",
    "            #'xgboost__gamma': [0.1, 0.5, 1,3],                     # Minimum loss reduction required for a split\n",
    "            #'xgboost__reg_alpha': [0.01, 0.1,0.5,1],                    # L1 regularization term on weights\n",
    "            #'xgboost__reg_lambda': [1, 1.5, 2],                      # L2 regularization term on weights\n",
    "            'xgboost__scale_pos_weight': [1, 5, 10]\n",
    "            }),\n",
    "    #'Logistic_Regression': (LogisticRegression(solver='liblinear'), {'logistic_regression__C': [0.1, 1, 10]}),\n",
    "    #'SVM': (SVC(probability=True), {'svm__C': [0.1, 1, 10], 'svm__kernel': ['linear', 'rbf']}),\n",
    "    #'NN': (MLPClassifier(max_iter=1000), {'nn__hidden_layer_sizes': [(10,), (50,), (100,)], 'nn__activation': ['relu', 'tanh']}),\n",
    "}\n",
    "\n",
    "# Initialize list to store predictions from each model\n",
    "\n",
    "ensemble_predictions = []\n",
    "ensemble_probabilities = []\n",
    "\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "    # Create a pipeline for preprocessing and model training\n",
    "    pipeline = Pipeline([\n",
    "        (model_name.lower(), model)\n",
    "    ])\n",
    "\n",
    "    # Perform hyperparameter tuning using GridSearchCV with AUC score\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='precision',n_jobs=8)\n",
    "    grid_search.fit(X_train_final, y_train_final)\n",
    "\n",
    "    # Get the best model from the grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Make predictions and predict probabilities on the test set\n",
    "    y_pred = best_model.predict(X_test_final)\n",
    "    y_prob = best_model.predict_proba(X_test_final)[:, 1]  # Probability for the positive class\n",
    "    ensemble_predictions.append(y_pred)\n",
    "    ensemble_probabilities.append(y_prob)\n",
    "\n",
    "    # Evaluate the model using accuracy, F1-score, and AUC\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
    "    print(f\"{model_name} F1 Score: {f1}\")\n",
    "    print(f\"{model_name} AUC: {auc}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Implement ensemble method (majority voting for predictions, average for probabilities)\n",
    "# ensemble_predictions = np.array(ensemble_predictions)\n",
    "# ensemble_pred_final = mode(ensemble_predictions, axis=0)[0].flatten()\n",
    "\n",
    "# # Average the probabilities for the ensemble AUC\n",
    "# ensemble_probabilities = np.mean(ensemble_probabilities, axis=0)\n",
    "\n",
    "# # Evaluate the ensemble model using accuracy, F1-score, and AUC\n",
    "# ensemble_accuracy = accuracy_score(y_test, ensemble_pred_final)\n",
    "# ensemble_f1 = f1_score(y_test, ensemble_pred_final)\n",
    "# ensemble_auc = roc_auc_score(y_test, ensemble_probabilities)\n",
    "# print(\"Ensemble Accuracy:\", ensemble_accuracy)\n",
    "# print(\"Ensemble F1 Score:\", ensemble_f1)\n",
    "# print(\"Ensemble AUC:\", ensemble_auc)\n",
    "# print(classification_report(y_test, ensemble_pred_final))\n",
    "\n",
    "with open(f'xgboost_embedding_{data_size}_{version}.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Location</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.380845</td>\n",
       "      <td>-0.919097</td>\n",
       "      <td>0.797135</td>\n",
       "      <td>2.028643</td>\n",
       "      <td>0.830206</td>\n",
       "      <td>-0.587897</td>\n",
       "      <td>-0.809677</td>\n",
       "      <td>-0.002741</td>\n",
       "      <td>0.429119</td>\n",
       "      <td>-0.628006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186046</td>\n",
       "      <td>-0.222702</td>\n",
       "      <td>0.905786</td>\n",
       "      <td>-0.695474</td>\n",
       "      <td>0.674217</td>\n",
       "      <td>-0.574596</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>-1.302847</td>\n",
       "      <td>-0.978701</td>\n",
       "      <td>-1.300178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.255708</td>\n",
       "      <td>-0.919097</td>\n",
       "      <td>0.624982</td>\n",
       "      <td>0.479407</td>\n",
       "      <td>2.139031</td>\n",
       "      <td>-1.090120</td>\n",
       "      <td>-0.228398</td>\n",
       "      <td>-0.269642</td>\n",
       "      <td>-0.213726</td>\n",
       "      <td>-0.653717</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.247641</td>\n",
       "      <td>0.831428</td>\n",
       "      <td>-0.210775</td>\n",
       "      <td>0.417983</td>\n",
       "      <td>-1.319875</td>\n",
       "      <td>1.101192</td>\n",
       "      <td>-0.760271</td>\n",
       "      <td>1.106522</td>\n",
       "      <td>0.471580</td>\n",
       "      <td>-1.654339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.735400</td>\n",
       "      <td>1.087442</td>\n",
       "      <td>-1.182620</td>\n",
       "      <td>-0.450134</td>\n",
       "      <td>-0.639364</td>\n",
       "      <td>-0.238149</td>\n",
       "      <td>0.045391</td>\n",
       "      <td>0.849737</td>\n",
       "      <td>-0.784145</td>\n",
       "      <td>-0.576590</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.766205</td>\n",
       "      <td>0.418259</td>\n",
       "      <td>2.197462</td>\n",
       "      <td>-0.133819</td>\n",
       "      <td>-0.422083</td>\n",
       "      <td>0.699439</td>\n",
       "      <td>-0.119825</td>\n",
       "      <td>-0.025478</td>\n",
       "      <td>-0.751724</td>\n",
       "      <td>-0.013726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.818824</td>\n",
       "      <td>1.087442</td>\n",
       "      <td>-1.354773</td>\n",
       "      <td>2.028643</td>\n",
       "      <td>-0.661485</td>\n",
       "      <td>0.544034</td>\n",
       "      <td>-1.295379</td>\n",
       "      <td>1.955023</td>\n",
       "      <td>-0.717170</td>\n",
       "      <td>-0.858801</td>\n",
       "      <td>...</td>\n",
       "      <td>1.626604</td>\n",
       "      <td>0.096559</td>\n",
       "      <td>-0.308833</td>\n",
       "      <td>0.374799</td>\n",
       "      <td>-0.522339</td>\n",
       "      <td>-0.520333</td>\n",
       "      <td>-1.468355</td>\n",
       "      <td>1.667375</td>\n",
       "      <td>-2.012132</td>\n",
       "      <td>2.198260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.818824</td>\n",
       "      <td>1.087442</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>-0.450134</td>\n",
       "      <td>-0.188096</td>\n",
       "      <td>-0.224956</td>\n",
       "      <td>0.679287</td>\n",
       "      <td>1.140302</td>\n",
       "      <td>0.655224</td>\n",
       "      <td>0.485271</td>\n",
       "      <td>...</td>\n",
       "      <td>1.136586</td>\n",
       "      <td>-0.255621</td>\n",
       "      <td>0.844490</td>\n",
       "      <td>-0.623350</td>\n",
       "      <td>1.510537</td>\n",
       "      <td>-0.916066</td>\n",
       "      <td>1.234783</td>\n",
       "      <td>1.747175</td>\n",
       "      <td>-1.182524</td>\n",
       "      <td>1.181839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 389 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age       Sex  Body_Part  Location  Product_1         0         1  \\\n",
       "0 -0.380845 -0.919097   0.797135  2.028643   0.830206 -0.587897 -0.809677   \n",
       "1 -0.255708 -0.919097   0.624982  0.479407   2.139031 -1.090120 -0.228398   \n",
       "2 -0.735400  1.087442  -1.182620 -0.450134  -0.639364 -0.238149  0.045391   \n",
       "3 -0.818824  1.087442  -1.354773  2.028643  -0.661485  0.544034 -1.295379   \n",
       "4 -0.818824  1.087442   0.495868 -0.450134  -0.188096 -0.224956  0.679287   \n",
       "\n",
       "          2         3         4  ...       374       375       376       377  \\\n",
       "0 -0.002741  0.429119 -0.628006  ... -0.186046 -0.222702  0.905786 -0.695474   \n",
       "1 -0.269642 -0.213726 -0.653717  ... -1.247641  0.831428 -0.210775  0.417983   \n",
       "2  0.849737 -0.784145 -0.576590  ... -1.766205  0.418259  2.197462 -0.133819   \n",
       "3  1.955023 -0.717170 -0.858801  ...  1.626604  0.096559 -0.308833  0.374799   \n",
       "4  1.140302  0.655224  0.485271  ...  1.136586 -0.255621  0.844490 -0.623350   \n",
       "\n",
       "        378       379       380       381       382       383  \n",
       "0  0.674217 -0.574596  0.007002 -1.302847 -0.978701 -1.300178  \n",
       "1 -1.319875  1.101192 -0.760271  1.106522  0.471580 -1.654339  \n",
       "2 -0.422083  0.699439 -0.119825 -0.025478 -0.751724 -0.013726  \n",
       "3 -0.522339 -0.520333 -1.468355  1.667375 -2.012132  2.198260  \n",
       "4  1.510537 -0.916066  1.234783  1.747175 -1.182524  1.181839  \n",
       "\n",
       "[5 rows x 389 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.48388719, -1.44084903, -1.39781088, -1.35477273, -1.31173458,\n",
       "       -1.26869643, -1.22565828, -1.18262013, -1.13958198,  0.45282959,\n",
       "        0.49586774,  0.53890589,  0.62498219,  0.66802035,  0.7110585 ,\n",
       "        0.75409665,  0.7971348 ,  1.01232555,  1.0553637 ,  1.18447815,\n",
       "        1.2275163 ,  1.27055445])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_body_parts = X_test_final['Body_Part'].unique()\n",
    "scaled_body_parts.sort()\n",
    "scaled_body_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68951863 0.9617856\n",
      "0.16811895 0.7241533\n",
      "0.76339394 0.97560763\n",
      "0.7927586 0.9804928\n",
      "0.72279125 0.9792716\n",
      "0.83525884 0.98364496\n",
      "0.85460955 0.99233586\n",
      "0.7927562 0.9863167\n",
      "0.971513 0.9867446\n",
      "0.8203353 0.9721784\n"
     ]
    }
   ],
   "source": [
    "for index, row in X_test_final[:10].iterrows():\n",
    "    prob = []\n",
    "    for body_part in scaled_body_parts:\n",
    "        current_sample = row.copy()\n",
    "        current_sample['Body_Part'] = body_part\n",
    "        # print(current_sample)\n",
    "        prob.append(best_model.predict_proba([current_sample])[0][0])\n",
    "    prob.sort()\n",
    "    print(prob[0], prob[-1]) # min max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "neiss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
