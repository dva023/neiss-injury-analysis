{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269f3b5c-4817-4322-a446-06678cd7ee2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Alan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Alan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Alan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\Alan\\Desktop\\dva_project_test\\tabpy_venv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "C:\\Users\\Alan\\Desktop\\dva_project_test\\tabpy_venv\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alan\\Desktop\\dva_project_test\\tabpy_venv\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.5.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "with open('X_scaler_10p_v0.pkl', 'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "\n",
    "with open('xgboost_embedding_10p_v0.pkl', 'rb') as file:\n",
    "    best_model = pickle.load(file)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "revision = None  # Replace with the specific revision to ensure reproducibility if the model is updated.\n",
    "model = SentenceTransformer(\"avsolatorio/GIST-small-Embedding-v0\", revision=revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3442568-2779-48c5-96f7-f4aaeac7a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdpt_dict={}\n",
    "bdpt_dict[30]='SHOULDER'\n",
    "bdpt_dict[31]='UPPERTRUNK'\n",
    "bdpt_dict[32]='ELBOW'\n",
    "bdpt_dict[33]='LOWERARM'\n",
    "bdpt_dict[34]='WRIST'\n",
    "bdpt_dict[35]='KNEE'\n",
    "bdpt_dict[36]='LOWERLEG'\n",
    "bdpt_dict[37]='ANKLE'\n",
    "bdpt_dict[38]='PUBICREGION'\n",
    "bdpt_dict[75]='HEAD'\n",
    "bdpt_dict[76]='FACE'\n",
    "bdpt_dict[77]='EYEBALL'\n",
    "bdpt_dict[78]='UPPERTRUNK(OLD)'\n",
    "bdpt_dict[79]='LOWERTRUNK'\n",
    "bdpt_dict[80]='UPPERARM'\n",
    "bdpt_dict[81]='UPPERLEG'\n",
    "bdpt_dict[82]='HAND'\n",
    "bdpt_dict[83]='FOOT'\n",
    "bdpt_dict[88]='MOUTH'\n",
    "bdpt_dict[89]='NECK'\n",
    "bdpt_dict[90]='LOWERARM(OLD)'\n",
    "bdpt_dict[91]='LOWERLEG(OLD)'\n",
    "bdpt_dict[92]='FINGER'\n",
    "bdpt_dict[93]='TOE'\n",
    "bdpt_dict[94]='EAR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913b9255-0020-4636-99bf-207895e58e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(X):\n",
    "\n",
    "    sample_df_single_record=pd.DataFrame(X,columns=['Age', 'Sex','Location','Product_1' ,'activity_at_injury', 'object_involved','injury_mechanism','More_details'])\n",
    "\n",
    "    sample_df_single_record[\"Age\"] = pd.to_numeric(sample_df_single_record[\"Age\"])\n",
    "    sample_df_single_record[\"Sex\"] = pd.to_numeric(sample_df_single_record[\"Sex\"])\n",
    "    sample_df_single_record[\"Location\"] = pd.to_numeric(sample_df_single_record[\"Location\"])\n",
    "    sample_df_single_record[\"Product_1\"] = pd.to_numeric(sample_df_single_record[\"Product_1\"])\n",
    "\n",
    "    sample_df_single_record['Narrative']=sample_df_single_record[\"activity_at_injury\"].astype(str) + ' '+sample_df_single_record[\"injury_mechanism\"].astype(str)+ ' ' + sample_df_single_record[\"object_involved\"].astype(str)+' '+sample_df_single_record[\"More_details\"].astype(str)\n",
    "\n",
    "    Embedding_df=pd.DataFrame(model.encode(sample_df_single_record['Narrative'], convert_to_tensor=True).numpy())\n",
    "    Embedding_df.columns=Embedding_df.columns.astype(str)\n",
    "\n",
    "    sample_df_single_record_2=sample_df_single_record[[\"Age\",\"Sex\",\"Location\",\"Product_1\"]]\n",
    "\n",
    "    return Embedding_df,sample_df_single_record_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04afb55f-13f4-44a8-9f22-99a9dc1dc401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_prediction(bdpt_dict,data_ready,scaler,best_model): #,sematic_distance_bert\n",
    "\n",
    "\n",
    "    prob_out={}\n",
    "\n",
    "    k=0\n",
    "\n",
    "    for i in bdpt_dict:\n",
    "        data_ready.at[0,'Body_Part']=i\n",
    "\n",
    "        X_test_scaled = scaler.transform(data_ready.select_dtypes(include=['number']))\n",
    "        X_test_final=pd.DataFrame(X_test_scaled, columns=data_ready.select_dtypes(include=['number']).columns)\n",
    "        y_prob = best_model.predict_proba(X_test_final)[:, 1][0]\n",
    "        #print(y_prob)\n",
    "        prob_out[str(i)]=y_prob\n",
    "        k+=1\n",
    "\n",
    "    return prob_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b80690-325b-49e3-beb7-ab49202e7332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict_Body_parts_Prob(Age, Sex, Location, Product_1, activity_at_injury, object_involved, injury_mechanism, More_details):\n",
    " \n",
    "    X = np.column_stack([Age, Sex, Location, Product_1, activity_at_injury, object_involved, injury_mechanism, More_details])\n",
    "    embedding_df, sample_df_single_record_2 = create_df(X)\n",
    "    data = {\"Body_Part\": [25]}\n",
    "    df_body = pd.DataFrame(data)\n",
    "    data_ready = pd.concat([sample_df_single_record_2[['Age', 'Sex']], df_body, sample_df_single_record_2[['Location', 'Product_1']], embedding_df], axis=1)\n",
    "    output = gen_prediction(bdpt_dict, data_ready, scaler, best_model)\n",
    "\n",
    "    probabilities = [float(value) for value in output.values()]\n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9c5a18c-c4fc-4e87-98f8-606926f6236d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.19397300481796265,\n",
       " 0.7552107572555542,\n",
       " 0.8747296929359436,\n",
       " 0.8099174499511719,\n",
       " 0.6968040466308594,\n",
       " 0.4638219177722931,\n",
       " 0.6632651686668396,\n",
       " 0.5643863677978516,\n",
       " 0.7467895746231079,\n",
       " 0.9490506052970886,\n",
       " 0.7697350382804871,\n",
       " 0.8380334973335266,\n",
       " 0.8356714844703674,\n",
       " 0.8356714844703674,\n",
       " 0.7234531044960022,\n",
       " 0.7650008201599121,\n",
       " 0.7650008201599121,\n",
       " 0.291553258895874,\n",
       " 0.6762338280677795,\n",
       " 0.3676290810108185,\n",
       " 0.3676290810108185,\n",
       " 0.3676290810108185,\n",
       " 0.3676290810108185,\n",
       " 0.19985206425189972,\n",
       " 0.18288663029670715]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predict_Body_parts_Prob(25, 1,1,1202 ,\"fall walk\", \"bike\",\"\",\"fall from bike when riding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2b8161f-aa58-4a1a-87fd-dbfb0671d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpy.tabpy_tools.client import Client\n",
    "\n",
    "deploy = Client('http://localhost:9004/')\n",
    "deploy.set_credentials(username='dva023', password='YL8bar-_3.jXGFet')\n",
    "deploy.deploy('tabpy_v5_2', Predict_Body_parts_Prob, 'tabpy v5.2 database test', override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7624a2be-92d4-4cb7-a8a0-354f491d7109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dva_kernel",
   "language": "python",
   "name": "dva_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
