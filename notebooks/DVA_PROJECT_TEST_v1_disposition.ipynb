{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load your data (replace with your actual data loading)\n",
        "# Assuming your data is in a CSV file named 'data.csv'\n",
        "data = pd.read_csv('azureml://subscriptions/512a781e-d15a-4734-adca-96ec827531cb/resourcegroups/xwang3306-rg/workspaces/DVA_PROJECT/datastores/workspaceblobstore/paths/UI/2024-10-16_040004_UTC/consolidated_cleaned_neiss_2014_2023.csv')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package punkt to /home/azureuser/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1730556707131
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(data.columns)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "['CPSC_Case_Number',\n 'Treatment_Date',\n 'Age',\n 'Sex',\n 'Race',\n 'Other_Race',\n 'Hispanic',\n 'Body_Part',\n 'Diagnosis',\n 'Other_Diagnosis',\n 'Body_Part_2',\n 'Diagnosis_2',\n 'Other_Diagnosis_2',\n 'Disposition',\n 'Location',\n 'Fire_Involvement',\n 'Product_1',\n 'Product_2',\n 'Product_3',\n 'Alcohol',\n 'Drug',\n 'Narrative',\n 'Stratum',\n 'PSU',\n 'Weight',\n 'Year',\n 'Month',\n 'Day']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730556718999
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data['Disposition_recode']=np.nan\n",
        "data.loc[((data['Disposition']==6) | (data['Disposition']==1)), 'Disposition_recode'] = 0\n",
        "data.loc[((data['Disposition']==2)), 'Disposition_recode'] = 1\n",
        "data.loc[((data['Disposition']==4)), 'Disposition_recode'] = 2\n",
        "data.loc[((data['Disposition']==5)), 'Disposition_recode'] = 3\n",
        "data.loc[((data['Disposition']==8)), 'Disposition_recode'] = 4\n",
        "data=data[data['Disposition_recode'].notna()]\n",
        "\n",
        "data['Disposition_recode_2']=0\n",
        "data.loc[((data['Disposition_recode']>0)), 'Disposition_recode_2'] = 1"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730557292326
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Disposition_recode'].value_counts()\n",
        "data['Disposition_recode_2'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "0    3142030\n1     378362\nName: Disposition_recode_2, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730557294292
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_after_dx(narrative):\n",
        "  if isinstance(narrative, str):\n",
        "    parts = narrative.split(\"DX\", 1)\n",
        "    if len(parts) > 1:\n",
        "      return parts[0]\n",
        "    else:\n",
        "      return narrative  # No \"DX:\" found, return the original string\n",
        "  else:\n",
        "    return narrative  # Not a string, return as is\n",
        "\n",
        "\n",
        "replace_list=['ANKLE', 'ARM', 'BODY_PART', 'CHEST', 'CONTUSION', 'CUT', 'EAR', 'ELBOW', 'EYE', 'FACE', 'FINGER', 'FOOT', 'FOREHEAD', 'FRACTURE', 'FX', 'HAND', 'HEAD', 'HIP', 'KNEE', 'LAC', 'LACERATION', 'LEG', 'LOC', 'LOSE', 'NECK', 'PAIN', 'SHOULDER', \n",
        "'SPRAIN', 'STRAIN', 'SWELL', 'THUMB', 'TOE', 'WRIST','ABRASION', 'ACHE', 'BREAK', 'BURN', 'CHIN', 'CUT', 'ER', 'FALL', 'FRACTURE', 'FX', 'HIT', 'INJURY', 'LACERATION', 'LIP', 'LOSE', 'LOC', 'MOUTH', 'NOSE', 'PAIN', 'RIB', 'SCALP', 'SPRAIN', 'STRAIN', 'SWELL', 'TOE', 'TWIST', 'WRIST']\n",
        "\n",
        "for i in replace_list:\n",
        "  data['Narrative'] = data['Narrative'].str.replace(i, '')\n",
        "\n",
        "data['Narrative'] = data['Narrative'].apply(remove_after_dx)\n",
        "data['Narrative'] = data['Narrative'].str.replace('YOM', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('YOF', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('YR', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('OLD', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('MALE', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('FEMALE', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace(' YO ', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('ACCIDENTALLY','')\n",
        "data['Narrative'] = data['Narrative'].str.replace('AGO', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('TODAY', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('YESTERDAY', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('PATIENT', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace(' PT ', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('INJURY', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('REPORT', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('HURT', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('INJ', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('FELL', 'FALL')\n",
        "data['Narrative'] = data['Narrative'].str.replace('INJURE', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('JURED', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace('URED', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace(' ED', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace(' RT ', '')\n",
        "data['Narrative'] = data['Narrative'].str.replace(' LT ', '')\n"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730559696793
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "core_col=['Disposition_recode_2','Age', 'Sex', 'Race','Location','Hispanic', 'Body_Part','Product_1' ,'Alcohol', 'Drug','Narrative']\n",
        "data_core=data[core_col]\n",
        "data_core_sample=data_core.sample(frac=0.1).reset_index(drop=True)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730559703371
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "\n",
        "corpus = data_core_sample['Narrative'].fillna('')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [token for token in tokens if token.isalpha() and token not in stopwords.words('english')]\n",
        "    tagged_tokens = nltk.pos_tag(tokens)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token, pos='v') for token, pos in tagged_tokens]\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "data_core_sample['Processed_Narrative'] = corpus.apply(preprocess_text)\n",
        "\n",
        "# Create a TfidfVectorizer object\n",
        "vectorizer = TfidfVectorizer(max_features=140, stop_words='english')\n",
        "\n",
        "# Fit and transform the processed text\n",
        "tfidf_matrix = vectorizer.fit_transform(data_core_sample['Processed_Narrative'])\n",
        "\n",
        "# Convert the TF-IDF matrix to a DataFrame\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Concatenate the TF-IDF features with your existing data\n",
        "data_ready = pd.concat([data_core_sample, tfidf_df], axis=1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package punkt_tab to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n[nltk_data]       date!\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730560092940
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(data_ready.columns)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "['Disposition_recode_2',\n 'Age',\n 'Sex',\n 'Race',\n 'Location',\n 'Hispanic',\n 'Body_Part',\n 'Product_1',\n 'Alcohol',\n 'Drug',\n 'Narrative',\n 'Processed_Narrative',\n 'aft',\n 'anoth',\n 'ation',\n 'backwards',\n 'balance',\n 'ball',\n 'bar',\n 'baseball',\n 'basketball',\n 'bathroom',\n 'bed',\n 'bend',\n 'bicycle',\n 'bike',\n 'body',\n 'bottle',\n 'box',\n 'break',\n 'broth',\n 'car',\n 'carpet',\n 'carry',\n 'catch',\n 'cause',\n 'cd',\n 'chair',\n 'class',\n 'clean',\n 'climb',\n 'come',\n 'concrete',\n 'corn',\n 'couch',\n 'day',\n 'days',\n 'develop',\n 'dog',\n 'door',\n 'dress',\n 'drink',\n 'drop',\n 'excise',\n 'facial',\n 'fe',\n 'feet',\n 'felt',\n 'fence',\n 'flight',\n 'floor',\n 'fore',\n 'forward',\n 'game',\n 'glass',\n 'grind',\n 'gym',\n 'hd',\n 'heavy',\n 'helmet',\n 'home',\n 'hot',\n 'house',\n 'ing',\n 'jump',\n 'kick',\n 'kitchen',\n 'knife',\n 'ladd',\n 'land',\n 'leave',\n 'lift',\n 'lose',\n 'low',\n 'metal',\n 'miss',\n 'mom',\n 'moth',\n 'nail',\n 'night',\n 'nurse',\n 'open',\n 'ov',\n 'park',\n 'pass',\n 'piece',\n 'play',\n 'pool',\n 'pop',\n 'practice',\n 'present',\n 'pull',\n 'punch',\n 'push',\n 'rid',\n 'right',\n 'ring',\n 'roll',\n 'run',\n 'saw',\n 'school',\n 'scoot',\n 'shoe',\n 'sit',\n 'skateboard',\n 'slide',\n 'socc',\n 'sp',\n 'speed',\n 'stairs',\n 'stand',\n 'start',\n 'state',\n 'step',\n 'stick',\n 'strike',\n 'sts',\n 'sustain',\n 'swallow',\n 'swim',\n 'swing',\n 'table',\n 'throw',\n 'tile',\n 'ting',\n 'toilet',\n 'toy',\n 'trampoline',\n 'trip',\n 'try',\n 'upp',\n 'use',\n 'walk',\n 'wall',\n 'wat',\n 'weight',\n 'wet',\n 'window',\n 'wing',\n 'wood',\n 'wooden',\n 'work']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730560110493
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, classification_report, accuracy_score, roc_auc_score\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = data_ready.drop(['Disposition_recode_2','Narrative','Processed_Narrative'], axis=1)  # ,'Processed_Narrative'] Replace 'target_variable' with your target column name\n",
        "y = data_ready['Disposition_recode_2']\n",
        "\n",
        "# Encode target variable if it's categorical\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a scaler for numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.select_dtypes(include=['number']))\n",
        "X_test_scaled = scaler.transform(X_test.select_dtypes(include=['number']))\n",
        "\n",
        "# Convert scaled features back to DataFrame\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.select_dtypes(include=['number']).columns)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.select_dtypes(include=['number']).columns)\n",
        "\n",
        "# Combine scaled numerical features with categorical features\n",
        "X_train_final = X_train_scaled_df.copy()\n",
        "X_test_final = X_test_scaled_df.copy()\n",
        "\n",
        "\n",
        "# Define models and their parameter grids for hyperparameter tuning\n",
        "models = {\n",
        "    'KNN': (KNeighborsClassifier(), {'knn__n_neighbors': [3, 5, 7]}),\n",
        "    'Random_Forest': (RandomForestClassifier(), {'random_forest__n_estimators': [100, 200], 'random_forest__max_depth': [4, 8]}),\n",
        "    'XGBoost': (XGBClassifier(objective='binary:logistic'), {'xgboost__learning_rate': [0.1, 0.01], 'xgboost__max_depth': [3, 5]})\n",
        "}\n",
        "\n",
        "# Initialize list to store predictions from each model\n",
        "ensemble_predictions = []\n",
        "ensemble_probabilities = []\n",
        "\n",
        "for model_name, (model, param_grid) in models.items():\n",
        "    print(f\"Training {model_name}...\")\n",
        "\n",
        "    # Create a pipeline for preprocessing and model training\n",
        "    pipeline = Pipeline([\n",
        "        (model_name.lower(), model)\n",
        "    ])\n",
        "\n",
        "    # Perform hyperparameter tuning using GridSearchCV with AUC score\n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='roc_auc')\n",
        "    grid_search.fit(X_train_final, y_train)\n",
        "\n",
        "    # Get the best model from the grid search\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Make predictions and predict probabilities on the test set\n",
        "    y_pred = best_model.predict(X_test_final)\n",
        "    y_prob = best_model.predict_proba(X_test_final)[:, 1]  # Probability for the positive class\n",
        "    ensemble_predictions.append(y_pred)\n",
        "    ensemble_probabilities.append(y_prob)\n",
        "\n",
        "    # Evaluate the model using accuracy, F1-score, and AUC\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_prob)\n",
        "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
        "    print(f\"{model_name} F1 Score: {f1}\")\n",
        "    print(f\"{model_name} AUC: {auc}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Implement ensemble method (majority voting for predictions, average for probabilities)\n",
        "ensemble_predictions = np.array(ensemble_predictions)\n",
        "ensemble_pred_final = mode(ensemble_predictions, axis=0)[0].flatten()\n",
        "\n",
        "# Average the probabilities for the ensemble AUC\n",
        "ensemble_probabilities = np.mean(ensemble_probabilities, axis=0)\n",
        "\n",
        "# Evaluate the ensemble model using accuracy, F1-score, and AUC\n",
        "ensemble_accuracy = accuracy_score(y_test, ensemble_pred_final)\n",
        "ensemble_f1 = f1_score(y_test, ensemble_pred_final)\n",
        "ensemble_auc = roc_auc_score(y_test, ensemble_probabilities)\n",
        "print(\"Ensemble Accuracy:\", ensemble_accuracy)\n",
        "print(\"Ensemble F1 Score:\", ensemble_f1)\n",
        "print(\"Ensemble AUC:\", ensemble_auc)\n",
        "print(classification_report(y_test, ensemble_pred_final))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training KNN...\nKNN Accuracy: 0.8862771275991365\nKNN F1 Score: 0.2047869699076373\nKNN AUC: 0.6948368117014451\n              precision    recall  f1-score   support\n\n           0       0.90      0.98      0.94     62792\n           1       0.42      0.14      0.20      7616\n\n    accuracy                           0.89     70408\n   macro avg       0.66      0.56      0.57     70408\nweighted avg       0.85      0.89      0.86     70408\n\nTraining Random_Forest...\nRandom_Forest Accuracy: 0.8918304738097943\nRandom_Forest F1 Score: 0.0\nRandom_Forest AUC: 0.7794048484890357\n              precision    recall  f1-score   support\n\n           0       0.89      1.00      0.94     62792\n           1       0.00      0.00      0.00      7616\n\n    accuracy                           0.89     70408\n   macro avg       0.45      0.50      0.47     70408\nweighted avg       0.80      0.89      0.84     70408\n\nTraining XGBoost...\n[15:52:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[15:53:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[15:53:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[15:54:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[15:54:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[15:55:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[15:56:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[15:56:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[15:56:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[15:57:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[15:57:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[15:58:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[15:59:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nXGBoost Accuracy: 0.8992302011135098\nXGBoost F1 Score: 0.2423918846769888\nXGBoost AUC: 0.8388078125886614\n              precision    recall  f1-score   support\n\n           0       0.91      0.99      0.95     62792\n           1       0.65      0.15      0.24      7616\n\n    accuracy                           0.90     70408\n   macro avg       0.78      0.57      0.59     70408\nweighted avg       0.88      0.90      0.87     70408\n\nEnsemble Accuracy: 0.8954664242699694\nEnsemble F1 Score: 0.1111111111111111\nEnsemble AUC: 0.8098330827366141\n              precision    recall  f1-score   support\n\n           0       0.90      1.00      0.94     62792\n           1       0.69      0.06      0.11      7616\n\n    accuracy                           0.90     70408\n   macro avg       0.80      0.53      0.53     70408\nweighted avg       0.88      0.90      0.85     70408\n\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/anaconda/envs/azureml_py38/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/tmp/ipykernel_3336/2154381961.py:72: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n  ensemble_pred_final = mode(ensemble_predictions, axis=0)[0].flatten()\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730563212933
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xxx"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'xxx' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mxxx\u001b[49m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xxx' is not defined"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1730509585767
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}